{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "bba74bd7",
   "metadata": {},
   "source": [
    "# TFM Final Project <img style=\"display: inline; align-right: 250px; position: absolute; right: 0px;\" src=\"files/Logo-AIT-Red600x-8.webp\" width=\"130\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d0501b5",
   "metadata": {},
   "source": [
    "ðŸ‘‰ Berta Pfaff</br>\n",
    "ðŸ‘‰ Sergio Salvador</br>\n",
    "ðŸ‘‰ Francesc VilarÃ³</br>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1686877",
   "metadata": {},
   "source": [
    "# Project motivation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5294dfc",
   "metadata": {},
   "source": [
    "**Movie recommendation systems have become increasingly popular in recent years** due to the vast amount of movies available for viewers to watch. With the rise of streaming services like Netflix, Hulu, and Amazon Prime, **it has become harder for viewers to decide which movie to watch**, given the plethora of options available.\n",
    "\n",
    "The proposed project aims to **build a movie recommender system using Python, leveraging the TMDB API to fetch movie metadata from 1980 until 2023**. The TMDB (The Movie Database) is an online database that provides comprehensive information related to movies, TV shows, and other forms of visual media. It is a community-driven platform that is curated and maintained by a team of editors and contributors who gather information from various sources, such as film studios, production companies, and fan communities, among others. The TMDB API (Application Programming Interface) provides developers with access to this wealth of data, allowing them to retrieve and use movie and TV show metadata in their own applications and projects.\n",
    "\n",
    "The project will consist of three main parts:\n",
    "\n",
    "1. **Database creation**: An Entity-Relationship model (ERM) will be first created, defining the entities, attributes, and relationships that need to be stored in the database. The next step is to create tables that correspond to the entities and attributes identified in the previous step. Each table should contain columns for the various attributes, along with appropriate data types and constraints.\n",
    "\n",
    "\n",
    "2. **Data fetching**: Asynchronous calls to the TMDB API will be used to fetch movie data, such as title, genre, release date, and ratings, among others. Traditional methods such as synchronous API requests would be to slow and inefficient for this aplication. Finally, data will be stored in a mySQL database, allowing for high performance and fast access.\n",
    "\n",
    "\n",
    "3. **EDA (Exploratory Data Analysis)**: Data visualization techniques will be applied to explore and understand the data. Graphs, charts, and histograms will be used to identify trends, patterns, and outliers, which can help improve the model's accuracy and obtain an overall understanding of the movie market in the last 40 years.\n",
    "\n",
    "\n",
    "4. **Recommendation model**: A model will be built using advanced machine learning algorithms. The model will be trained on the movie metadata to generate personalized movie recommendations. the proposed model will utilize a complex algorithm that takes into consideration numerous variables, such as the movie's plot overview, the cast of actors, and the directors involved in its production, among other factors, to ultimately <u>recommend a set of five other movies that share similarities and patterns with the original movie</u>. This comprehensive approach not only provides a reliable and accurate way to suggest new movie options to viewers but also ensures that the recommended movies align with the viewer's preferences and tastes, resulting in a highly personalized and satisfying viewing experience.\n",
    "\n",
    "Overall, this project aims to provide a convenient and personalized movie recommendation system that can help users discover new movies they will enjoy. Additionally, the project will also provide an opportunity to learn and apply several data science techniques learned throughout the master's degree, such as data retrieval, data visualization, and machine learning."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a0ceada",
   "metadata": {},
   "source": [
    "# Imported libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00323ac4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import mysql.connector\n",
    "import pandas as pd\n",
    "import warnings\n",
    "import random\n",
    "import requests\n",
    "import time\n",
    "from IPython.display import clear_output\n",
    "import csv\n",
    "from datetime import date, timedelta\n",
    "from tqdm import tqdm\n",
    "import ast\n",
    "import asyncio\n",
    "import aiohttp\n",
    "import os\n",
    "import json"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "061cddb2",
   "metadata": {},
   "source": [
    "## MySQL Workbench Database creation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d5451bb",
   "metadata": {},
   "source": [
    "### Connection to MySQL server"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48ebb7e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "warnings.filterwarnings(\"ignore\") # Warnings are disabled\n",
    "\n",
    "db = mysql.connector.connect(\n",
    "    host = \"localhost\",\n",
    "    user = \"root\",\n",
    "    password= \"12345\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "319e04c2",
   "metadata": {},
   "source": [
    "### Cursor object instantiation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67fdad25",
   "metadata": {},
   "outputs": [],
   "source": [
    "cursor = db.cursor()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f10f9b08",
   "metadata": {},
   "source": [
    "### Movies database creation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0aa5c3ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "cursor.execute(\"CREATE DATABASE TMDB\")\n",
    "db.commit()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d49612ba",
   "metadata": {},
   "source": [
    "### Conection to TMDB database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5fdc6a9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Connections\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "db = mysql.connector.connect(\n",
    "    host = \"localhost\",\n",
    "    user = \"root\",\n",
    "    password= \"12345\",\n",
    "    database= \"TMDB\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fbe725c3",
   "metadata": {},
   "source": [
    "## Entity-Relationship model (ERM)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef2c6c18",
   "metadata": {},
   "source": [
    "<img src=\"files/DB_ERM_v2.png\" style=\"width:700px\">"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a172817",
   "metadata": {},
   "source": [
    "## Table creation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "690c6444",
   "metadata": {},
   "source": [
    "### Primary table creation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "710b1a2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "cursor = db.cursor()\n",
    "query_movie = \"\"\"\n",
    "    CREATE TABLE movie(\n",
    "        id_movie int,\n",
    "        original_title varchar(300),\n",
    "        original_language varchar(20), \n",
    "        overview varchar(1000),\n",
    "        popularity float,\n",
    "        poster_path varchar(200),\n",
    "        release_date varchar(20),\n",
    "        title varchar(300),\n",
    "        vote_average float,\n",
    "        vote_count int,\n",
    "        budget int, \n",
    "        revenue bigint,\n",
    "        runtime int,\n",
    "        PRIMARY KEY (id_movie)\n",
    "    )\n",
    "\"\"\"\n",
    "\n",
    "cursor.execute(query_movie)\n",
    "db.commit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2c7ebe0",
   "metadata": {},
   "outputs": [],
   "source": [
    "cursor = db.cursor()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f410985a",
   "metadata": {},
   "source": [
    "### Secondary tables"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e72c3db",
   "metadata": {},
   "source": [
    "#### Streaming companies"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7873f80b",
   "metadata": {},
   "source": [
    "##### str_comp table creation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1f5777a",
   "metadata": {},
   "outputs": [],
   "source": [
    "query_str_comp = \"\"\"\n",
    "    CREATE TABLE str_comp (\n",
    "    id_str_comp int AUTO_INCREMENT,\n",
    "    name varchar(50),\n",
    "    PRIMARY KEY (id_str_comp)\n",
    ")\n",
    "\"\"\"\n",
    "\n",
    "cursor.execute(query_str_comp)\n",
    "db.commit()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf884840",
   "metadata": {},
   "source": [
    "##### movie_str_comp junction table creation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "518c9ac4",
   "metadata": {},
   "outputs": [],
   "source": [
    "query_movie_str_comp = \"\"\"\n",
    "    CREATE TABLE movie_str_comp (\n",
    "    id_mov_str_comp int AUTO_INCREMENT,\n",
    "    id_movie int,\n",
    "    id_str_comp int,\n",
    "    PRIMARY KEY (id_mov_str_comp),\n",
    "    FOREIGN KEY (id_movie) REFERENCES movie(id_movie),\n",
    "    FOREIGN KEY (id_str_comp) REFERENCES str_comp(id_str_comp)\n",
    ")\n",
    "\"\"\"\n",
    "\n",
    "cursor.execute(query_movie_str_comp)\n",
    "db.commit()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8e15bd3",
   "metadata": {},
   "source": [
    "#### Production companies"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1eb91f49",
   "metadata": {},
   "source": [
    "##### prod_comp table creation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad43874b",
   "metadata": {},
   "outputs": [],
   "source": [
    "query_prod_comp = \"\"\"\n",
    "    CREATE TABLE prod_comp ( \n",
    "         id_prod_comp int NOT NULL,\n",
    "         name varchar (100),\n",
    "         origin_country varchar (20),\n",
    "\n",
    "         PRIMARY KEY (id_prod_comp)\n",
    "      )\n",
    "\"\"\"\n",
    "cursor.execute(query_prod_comp)\n",
    "db.commit()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39ce4afc",
   "metadata": {},
   "source": [
    "##### movie_prod_comp junction table creation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d787677d",
   "metadata": {},
   "outputs": [],
   "source": [
    "query_movie_prod_comp = \"\"\"\n",
    "    CREATE TABLE movie_prod_comp (\n",
    "        id_mov_prod_comp int AUTO_INCREMENT,\n",
    "        id_movie int,\n",
    "        id_prod_comp int,\n",
    "        \n",
    "        PRIMARY KEY (id_mov_prod_comp),\n",
    "        FOREIGN KEY (id_movie) REFERENCES movie(id_movie),\n",
    "        FOREIGN KEY (id_prod_comp) REFERENCES prod_comp(id_prod_comp)\n",
    "      )\n",
    "\"\"\"\n",
    "cursor.execute(query_movie_prod_comp)\n",
    "db.commit()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "763cb12d",
   "metadata": {},
   "source": [
    "#### Genres"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63debe16",
   "metadata": {},
   "source": [
    "##### genre table creation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76b74deb",
   "metadata": {},
   "outputs": [],
   "source": [
    "query_genre = \"\"\"\n",
    "    CREATE TABLE genre ( \n",
    "         id_genre int NOT NULL,\n",
    "         genre varchar (30),\n",
    "\n",
    "         PRIMARY KEY(id_genre)\n",
    "      )\n",
    "\"\"\"\n",
    "cursor.execute(query_genre)\n",
    "db.commit()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ed41106",
   "metadata": {},
   "source": [
    "##### movie_genre table creation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "785e1eec",
   "metadata": {},
   "outputs": [],
   "source": [
    "query_movie_genre = \"\"\"\n",
    "    CREATE TABLE movie_genre (\n",
    "        id_mov_genre int AUTO_INCREMENT,\n",
    "        id_movie int,\n",
    "        id_genre int,\n",
    "\n",
    "        PRIMARY KEY (id_mov_genre),\n",
    "        FOREIGN KEY (id_movie) REFERENCES movie(id_movie),\n",
    "        FOREIGN KEY (id_genre) REFERENCES genre(id_genre)\n",
    "      )\n",
    "\"\"\"\n",
    "cursor.execute(query_movie_genre)\n",
    "db.commit()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bee441bb",
   "metadata": {},
   "source": [
    "#### People"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7bc5787",
   "metadata": {},
   "source": [
    "##### _person_ table creation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "874a0313",
   "metadata": {},
   "outputs": [],
   "source": [
    "query_person = \"\"\"\n",
    "    CREATE TABLE person ( \n",
    "         id_person int NOT NULL,\n",
    "         name varchar (50),\n",
    "         gender int,\n",
    "\n",
    "         PRIMARY KEY (id_person)\n",
    "      )\n",
    "\"\"\"\n",
    "cursor.execute(query_person)\n",
    "db.commit()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27a52eac",
   "metadata": {},
   "source": [
    "##### job table creation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1445d87a",
   "metadata": {},
   "outputs": [],
   "source": [
    "query_job = \"\"\"\n",
    "    CREATE TABLE job (\n",
    "        id_job int AUTO_INCREMENT,\n",
    "        job_name varchar(50),\n",
    "        \n",
    "        PRIMARY KEY (id_job)\n",
    "      )\n",
    "\"\"\"\n",
    "cursor.execute(query_job)\n",
    "db.commit()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ff1dbc1",
   "metadata": {},
   "source": [
    "##### movie_person junction table creation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67a42cbd",
   "metadata": {},
   "outputs": [],
   "source": [
    "query_movie_person = \"\"\"\n",
    "    CREATE TABLE movie_person ( \n",
    "         id_mov_person int AUTO_INCREMENT,\n",
    "         id_movie int,\n",
    "         id_person int,\n",
    "         id_job int,\n",
    "\n",
    "         PRIMARY KEY (id_mov_person),\n",
    "         FOREIGN KEY (id_movie) REFERENCES movie(id_movie),\n",
    "         FOREIGN KEY (id_person) REFERENCES person(id_person),\n",
    "         FOREIGN KEY (id_job) REFERENCES job(id_job)\n",
    "      )\n",
    "\"\"\"\n",
    "cursor.execute(query_movie_person)\n",
    "db.commit()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74ec106d",
   "metadata": {},
   "source": [
    "## API key"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "42025516",
   "metadata": {},
   "outputs": [],
   "source": [
    "api_key = \"ac6862efab2ddf803567630c9f474ab8\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b96a2a6b",
   "metadata": {},
   "source": [
    "## Independent tables generation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6551e631",
   "metadata": {},
   "source": [
    "### Genres table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd67c66c",
   "metadata": {},
   "outputs": [],
   "source": [
    "url_genres = \"https://api.themoviedb.org/3/genre/movie/list\"\n",
    "\n",
    "query_params = {\n",
    "                \"api_key\": api_key,\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4406a8a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_genres(url_genres, query_params):\n",
    "    \"\"\"\n",
    "    This function sends a request to the TMDB API and returns a list of tuples \n",
    "    containing the id and name of all the available genres.\n",
    "    \"\"\"\n",
    "    response = requests.get(url_genres, query_params).json()\n",
    "    \n",
    "    genres = [(genre['id'], genre['name']) for genre in response['genres']]\n",
    "    \n",
    "    return genres"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6094ef4",
   "metadata": {},
   "outputs": [],
   "source": [
    "genres = get_genres(url_genres, query_params)\n",
    "genres[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54041e7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def populate_genre(genres):\n",
    "    insert_query = \"\"\"\n",
    "    INSERT INTO genre\n",
    "    (id_genre, genre)\n",
    "    VALUES(%s, %s)\n",
    "    \"\"\"\n",
    "    \n",
    "    cursor.executemany(insert_query, genres)\n",
    "    db.commit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0bb4c64b",
   "metadata": {},
   "outputs": [],
   "source": [
    "populate_genre(genres)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a3fb00f",
   "metadata": {},
   "source": [
    "### Streaming Companies table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60f1aaae",
   "metadata": {},
   "outputs": [],
   "source": [
    "url_str_comps = \"https://api.themoviedb.org/3/watch/providers/movie\"\n",
    "\n",
    "query_params_str_comps = {\n",
    "                \"api_key\": api_key,\n",
    "                \"watch-region\": \"ES\"\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dee6a5b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_str_comps(url_str_comps, query_params_str_comp):\n",
    "    \"\"\"\n",
    "    This function sends a request to the TMDB API and returns a list of tuples \n",
    "    containing the id and name of all the available streaming companies. \n",
    "    \"\"\"\n",
    "    response = requests.get(url_str_comps, query_params_str_comps).json()\n",
    "    str_comps = [(result['provider_id'], result['provider_name']) for result in response['results']]\n",
    "    \n",
    "    return str_comps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "361f542e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "str_comps = get_str_comps(url_str_comps, query_params_str_comps)\n",
    "str_comps[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "794ebea4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def populate_str_comps(str_comps):\n",
    "    insert_query = \"\"\"\n",
    "    INSERT INTO str_comp\n",
    "    (id_str_comp, name)\n",
    "    VALUES(%s, %s)\n",
    "    \"\"\"\n",
    "    \n",
    "    cursor.executemany(insert_query, str_comps)\n",
    "    db.commit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9d60989",
   "metadata": {},
   "outputs": [],
   "source": [
    "populate_str_comps(str_comps)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e065abc7",
   "metadata": {},
   "source": [
    "### Jobs table "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93181799",
   "metadata": {},
   "outputs": [],
   "source": [
    "jobs = ['Actor', 'Director','Screenplay']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "209cd6ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "def populate_job(jobs):\n",
    "    insert_query = \"\"\"\n",
    "    INSERT INTO job\n",
    "    (job_name)\n",
    "    VALUES(%s)\n",
    "    \"\"\"\n",
    "    for job in jobs:\n",
    "        cursor.execute(insert_query, [job])\n",
    "    db.commit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3c0eaed",
   "metadata": {},
   "outputs": [],
   "source": [
    "populate_job(jobs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e1cecc1",
   "metadata": {},
   "source": [
    "## Movies IDs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32840434",
   "metadata": {},
   "outputs": [],
   "source": [
    "# parameters\n",
    "\n",
    "start_year = 1980\n",
    "end_year = 2023\n",
    "\n",
    "url_discover = \"https://api.themoviedb.org/3/discover/movie\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ee91fb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def month_range_dict(start_year, end_year):\n",
    "    \"\"\"\n",
    "    Returns a dictionary that maps the first day of a month to the last day of the month, given a start and end year.\n",
    "    \"\"\"\n",
    "    month_range = {}\n",
    "    start_date = date(start_year, 1, 1)\n",
    "    end_date = date(end_year, 12, 31)\n",
    "\n",
    "    # Iterate over all months between start and end dates\n",
    "    while start_date < end_date:\n",
    "        year = start_date.year\n",
    "        month = start_date.month\n",
    "        last_day = (date(year, month, 1) + timedelta(days=32)).replace(day=1) - timedelta(days=1)\n",
    "        month_range[start_date.strftime('%Y-%m-%d')] = last_day.strftime('%Y-%m-%d')\n",
    "        start_date = last_day + timedelta(days=1)\n",
    "\n",
    "    return month_range"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bfb9f220",
   "metadata": {},
   "outputs": [],
   "source": [
    "def total_pages(start_date, end_date, api_key, url_discover):\n",
    "    param = {'api_key': api_key,\n",
    "             'primary_release_date.gte': start_date,\n",
    "             'primary_release_date.lte': end_date,\n",
    "             'page': 500}\n",
    "    \n",
    "    return requests.get(url_discover, param).json()['total_pages']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d1e5e50",
   "metadata": {},
   "outputs": [],
   "source": [
    "total_pages('1980-01-01', '2023-12-31', api_key, url_discover)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0bdf29ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "def params_generator(start_year, end_year, api_key, url_discover):\n",
    "    params = []\n",
    "    total_pag = 0\n",
    "    \n",
    "    for start_date, end_date in month_range_dict(start_year, end_year).items():\n",
    "        \n",
    "        total_pag = total_pages(start_date, end_date, api_key, url_discover)\n",
    "        \n",
    "        page = 1\n",
    "        \n",
    "        while page <= total_pag:\n",
    "            params.append({\n",
    "                \"api_key\": api_key,\n",
    "                \"primary_release_date.gte\": start_date,\n",
    "                \"primary_release_date.lte\": end_date,\n",
    "                \"page\": page\n",
    "            })\n",
    "            page += 1\n",
    "            \n",
    "    if not os.path.exists('data'):\n",
    "        os.makedirs('data')\n",
    "        \n",
    "    fieldnames = ['api_key', 'primary_release_date.gte', 'primary_release_date.lte', 'page']\n",
    "    \n",
    "    with open(f'data/discover_params_{start_year}_{end_year}.csv', 'w', newline='') as csvfile:\n",
    "        writer = csv.DictWriter(csvfile, fieldnames=fieldnames)\n",
    "        writer.writeheader()\n",
    "        for param in params:\n",
    "            writer.writerow(param)\n",
    "        \n",
    "    return params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e43e1e30",
   "metadata": {},
   "outputs": [],
   "source": [
    "params = params_generator(start_year, end_year, api_key, url_discover)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d39272b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_discover_params_csv(csv_filepath):\n",
    "    json_list = []\n",
    "    with open(csv_filepath, 'r', newline='') as csvfile:\n",
    "        reader = csv.DictReader(csvfile)\n",
    "        for row in reader:\n",
    "            json_list.append(row)\n",
    "    return json_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a1effa4",
   "metadata": {},
   "outputs": [],
   "source": [
    "params = read_discover_params_csv(f'data/discover_params_{start_year}_{end_year}.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90286b54",
   "metadata": {},
   "outputs": [],
   "source": [
    "params[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0555b6af",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_tasks_discover(session, url, params, processed_pages):\n",
    "    tasks = []\n",
    "    for i, param in enumerate(params):\n",
    "        if processed_pages[i]==0:\n",
    "            tasks.append((i, session.get(url, params=param, timeout = 15)))\n",
    "    return tasks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c316a0f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "processed_pages = {}\n",
    "\n",
    "for i in range(len(params)):\n",
    "    processed_pages[i]=0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c54460f",
   "metadata": {},
   "outputs": [],
   "source": [
    "processed_pages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e81d3d4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "async def discover_api_call(url, params, processed_pages, max_tries=3):\n",
    "    results=[]\n",
    "    exceptions = []\n",
    "    page_counter = 0\n",
    "    try_counter = 0\n",
    "    max_step = 1000\n",
    "    step = max_step\n",
    "    while try_counter < max_tries:\n",
    "        async with aiohttp.ClientSession() as session:\n",
    "            tasks = get_tasks_discover(session, url, params, processed_pages)\n",
    "            if not tasks:\n",
    "                return results, exceptions\n",
    "            if len(tasks) < max_step:\n",
    "                step = len(tasks)\n",
    "            for i in range(0, len(tasks), step): #len(tasks)\n",
    "                batch = tasks[i:i+step]\n",
    "                responses = await asyncio.gather(*[t[1] for t in batch], return_exceptions=True)\n",
    "                #await asyncio.sleep()\n",
    "                for j, response in enumerate(responses):\n",
    "                    try:\n",
    "                        movies_page = await response.json()\n",
    "                        results.append(movies_page['results'])\n",
    "                        processed_pages[batch[j][0]] = 1\n",
    "                        page_counter += 1\n",
    "                        clear_output(wait=True)\n",
    "                        print(f'{page_counter} pages out of {len(params)} have been fetched')\n",
    "                    except:\n",
    "                        exceptions.append(response)\n",
    "        try_counter += 1\n",
    "    return results, exceptions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2521e28b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "start = time.monotonic()\n",
    "discovered_movies, exceptions = await discover_api_call(url_discover, params, processed_pages)\n",
    "end = time.monotonic()\n",
    "\n",
    "print(f'Elapsed time: {round(end - start, 2)} seconds')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d69d871b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_movie_ids(discovered_movies):\n",
    "    \n",
    "    if not os.path.exists('data'):\n",
    "        os.makedirs('data')\n",
    "    \n",
    "    movie_ids = {movie['id']: 0\n",
    "            for page in discovered_movies\n",
    "            for movie in page}\n",
    "    \n",
    "    with open(f'data/ids_movies_{start_year}-{end_year}.csv', 'w') as f:\n",
    "        for key in movie_ids.keys():\n",
    "            f.write(\"%s,%s\\n\"%(key,movie_ids[key]))\n",
    "            \n",
    "    print(f'{len(movie_ids)} movie IDs have been saved succesfully')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "089d9890",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "get_movie_ids(discovered_movies)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "393c2dfc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def csv_to_dict(filepath):\n",
    "    # create an empty dictionary to store the CSV data\n",
    "    csv_dict = {}\n",
    "\n",
    "    # open the CSV file in read mode\n",
    "    with open(filepath, 'r') as f:\n",
    "\n",
    "    # create a reader object to read the CSV data\n",
    "        reader = csv.reader(f)\n",
    "\n",
    "    # loop through each row in the CSV file\n",
    "        for row in reader:\n",
    "            csv_dict[row[0]] = ast.literal_eval(row[1])\n",
    "\n",
    "    return csv_dict"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "643db229",
   "metadata": {},
   "source": [
    "## Movie details"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "662362ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "movie = requests.get(\"https://api.themoviedb.org/3/movie/337800\", params = details_params).json()\n",
    "movie"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4f07131",
   "metadata": {},
   "outputs": [],
   "source": [
    "url_details = \"https://api.themoviedb.org/3/movie/\"\n",
    "\n",
    "details_params = {\n",
    "                \"api_key\": \"ac6862efab2ddf803567630c9f474ab8\",\n",
    "                \"append_to_response\": \"credits\"\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e072ac8e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "ids_movies = csv_to_dict(f'data/ids_movies_{start_year}-{end_year}.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f81f4d4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_tasks_details(session, url_details, details_params, ids_movies):\n",
    "    tasks = []\n",
    "    for id_movie, processing_state in ids_movies.items():\n",
    "        if processing_state==0:\n",
    "            tasks.append(session.get(url_details + str(id_movie), params=details_params, timeout = 15))\n",
    "    return tasks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7ae4580",
   "metadata": {},
   "outputs": [],
   "source": [
    "async def details_api_call(url, details_params, ids_movies, output_file, max_tries=3):\n",
    "    exceptions = []\n",
    "    movie_counter = 0\n",
    "    try_counter = 0\n",
    "    max_step = 1000\n",
    "    step = max_step\n",
    "    existing_ids = set()\n",
    "    if os.path.exists(output_file):\n",
    "        with open(output_file, \"r\") as f:\n",
    "            for line in f:\n",
    "                movie = json.loads(line)\n",
    "                existing_ids.add(str(movie['id']))\n",
    "    with open(output_file, \"a\") as f:\n",
    "        while try_counter < max_tries:\n",
    "            async with aiohttp.ClientSession() as session:\n",
    "                tasks = get_tasks_details(session, url, details_params, ids_movies)\n",
    "                if not tasks:\n",
    "                    return exceptions\n",
    "                if len(tasks) < max_step:\n",
    "                    step = len(tasks)\n",
    "                for i in range(0, len(tasks), step):\n",
    "                    batch = tasks[i:i+step]\n",
    "                    responses = await asyncio.gather(*batch, return_exceptions=True)\n",
    "                    for response in responses:\n",
    "                        try:\n",
    "                            movie = await response.json()\n",
    "                            if movie['id'] and str(movie['id']) not in existing_ids:\n",
    "                                json.dump(movie, f)\n",
    "                                f.write('\\n')\n",
    "                                existing_ids.add(str(movie['id']))\n",
    "                                ids_movies[str(movie['id'])] = 1\n",
    "                                movie_counter += 1\n",
    "                                clear_output(wait=True)\n",
    "                                print(f'{movie_counter} movies out of {len(ids_movies)} have been fetched')\n",
    "                        except:\n",
    "                            exceptions.append(response)\n",
    "            try_counter += 1\n",
    "    return exceptions\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed263c3c",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "start = time.monotonic()\n",
    "detailed_movies = await details_api_call(url_details, details_params, ids_movies, output_file = 'data/processed_movies_ids.jsonl')\n",
    "end = time.monotonic()\n",
    "\n",
    "print(f'Elapsed time: {round(end - start, 2)} seconds')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "480ea6d2",
   "metadata": {},
   "source": [
    "## Streaming companies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73d2deca",
   "metadata": {},
   "outputs": [],
   "source": [
    "ids_movies = csv_to_dict(f'data/ids_movies_{start_year}-{end_year}.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f05e4ca7",
   "metadata": {},
   "outputs": [],
   "source": [
    "str_comps_url = \"https://api.themoviedb.org/3/movie/\"\n",
    "\n",
    "str_comps_endpoint = \"/watch/providers\"\n",
    "\n",
    "str_comp_params = {\n",
    "                \"api_key\": api_key,\n",
    "                \"watch-region\": \"ES\"\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "828b06fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_tasks_str_comps(session, url_str_comp, str_comps_endpoint, str_comp_params, ids_movies):\n",
    "    tasks = []\n",
    "    for id_movie, processing_state in ids_movies.items():\n",
    "        if processing_state==0:\n",
    "            tasks.append(session.get(str_comps_url + str(id_movie) + str_comps_endpoint, params=str_comp_params, timeout = 15))\n",
    "    return tasks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7329940",
   "metadata": {},
   "outputs": [],
   "source": [
    "async def str_comp_api_call(str_comps_url, str_comps_endpoint, str_comp_params, ids_movies, output_file, max_tries=3):\n",
    "    exceptions = []\n",
    "    movie_counter = 0\n",
    "    try_counter = 0\n",
    "    max_step = 1000\n",
    "    step = max_step\n",
    "    existing_ids = set()\n",
    "    if os.path.exists(output_file):\n",
    "        with open(output_file, \"r\") as f:\n",
    "            for line in f:\n",
    "                movie = json.loads(line)\n",
    "                existing_ids.add(str(movie['id']))\n",
    "                movie_counter += 1\n",
    "                ids_movies[str(movie['id'])] = 1\n",
    "    with open(output_file, \"a\") as f:\n",
    "        while try_counter < max_tries:\n",
    "            async with aiohttp.ClientSession() as session:\n",
    "                tasks = get_tasks_str_comps(session, str_comps_url, str_comps_endpoint,str_comp_params, ids_movies)\n",
    "                if not tasks:\n",
    "                    return exceptions\n",
    "                if len(tasks) < max_step:\n",
    "                    step = len(tasks)\n",
    "                for i in range(0, len(tasks), step):\n",
    "                    batch = tasks[i:i+step]\n",
    "                    responses = await asyncio.gather(*batch, return_exceptions=True)\n",
    "                    for response in responses:\n",
    "                        try:\n",
    "                            str_comps = await response.json()\n",
    "                            if str(str_comps['id']) not in existing_ids:\n",
    "                                json.dump(str_comps, f)\n",
    "                                f.write('\\n')\n",
    "                                existing_ids.add(str(str_comps['id']))\n",
    "                                ids_movies[str(str_comps['id'])] = 1\n",
    "                                movie_counter += 1\n",
    "                                clear_output(wait=True)\n",
    "                                print(f'Watch providers for {movie_counter} movies out of {len(ids_movies)} have been fetched')\n",
    "                        except:\n",
    "                            exceptions.append(response)\n",
    "            try_counter += 1\n",
    "    return exceptions, movie_counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e2cb539",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "start = time.monotonic()\n",
    "exceptions, movie_counter = await str_comp_api_call(str_comps_url, str_comps_endpoint, str_comp_params, ids_movies, output_file = 'data/str_comps.jsonl', max_tries=3)\n",
    "end = time.monotonic()\n",
    "\n",
    "print(f'Elapsed time: {round(end - start, 2)} seconds')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12d4f3d4",
   "metadata": {},
   "source": [
    "## Table population"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "baa00f77",
   "metadata": {},
   "outputs": [],
   "source": [
    "def populate_movie(movies):\n",
    "    insert_query = \"\"\"\n",
    "    INSERT INTO movie\n",
    "    (id_movie, original_title, original_language, overview, popularity, poster_path, release_date, title, vote_average, vote_count, budget, revenue, runtime)\n",
    "    VALUES(%s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s)\n",
    "    \"\"\"\n",
    "    \n",
    "    records = [(m['id'], m['original_title'], m['original_language'], m['overview'], m['popularity'], m['poster_path'], m['release_date'], m['title'], m['vote_average'], m['vote_count'], m['budget'], m['revenue'], m['runtime']) for m in movies]\n",
    "    \n",
    "    cursor.executemany(insert_query, records)\n",
    "    \n",
    "    db.commit()\n",
    "    \n",
    "    return cursor.rowcount"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce3159c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def populate_prod_comp(movies):\n",
    "    insert_query = \"\"\"\n",
    "    INSERT IGNORE INTO prod_comp\n",
    "    (id_prod_comp, name, origin_country)\n",
    "    VALUES(%s, %s, %s)\n",
    "    \"\"\"\n",
    "    \n",
    "    prod_comps = [(prod_comp['id'], \n",
    "                   prod_comp['name'], \n",
    "                   prod_comp['origin_country']) \n",
    "                  for movie in movies\n",
    "                  for prod_comp in movie['production_companies']]\n",
    "                              \n",
    "    cursor.executemany(insert_query, prod_comps)\n",
    "    db.commit()\n",
    "    \n",
    "    return cursor.rowcount"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65bdbe9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def populate_movie_prod_comp(movies):\n",
    "    insert_query = \"\"\"\n",
    "    INSERT INTO movie_prod_comp\n",
    "    (id_movie, id_prod_comp)\n",
    "    VALUES(%s, %s)\n",
    "    \"\"\"\n",
    "    \n",
    "    movie_prod_comp = [(m['id'],\n",
    "                        prod_comp['id']) \n",
    "                       for m in movies \n",
    "                       for prod_comp in m['production_companies']]\n",
    "    \n",
    "    cursor.executemany(insert_query, movie_prod_comp)\n",
    "    \n",
    "    db.commit()\n",
    "    \n",
    "    return cursor.rowcount"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab3756ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "def populate_movie_genre(movies):\n",
    "    insert_query = \"\"\"\n",
    "    INSERT INTO movie_genre\n",
    "    (id_movie, id_genre)\n",
    "    VALUES(%s, %s)\n",
    "    \"\"\"\n",
    "    movie_genre = [(m['id'], \n",
    "                     genre['id']) \n",
    "                    for m in movies \n",
    "                    for genre in m['genres']]\n",
    "    \n",
    "    cursor.executemany(insert_query, movie_genre)\n",
    "    \n",
    "    db.commit()\n",
    "    \n",
    "    return cursor.rowcount"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a6d94e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def populate_person(movies, jobs):\n",
    "    insert_query = \"\"\"\n",
    "    INSERT IGNORE INTO person\n",
    "    (id_person, name, gender)\n",
    "    VALUES(%s, %s, %s)\n",
    "    \"\"\"\n",
    "    \n",
    "    actors = [(actor['id'], \n",
    "               actor['name'], \n",
    "               actor['gender']) \n",
    "              for m in movies \n",
    "              for actor in m['credits']['cast'][0:7]]\n",
    "    \n",
    "    crew = [(crew_mem['id'], \n",
    "             crew_mem['name'], \n",
    "             crew_mem['gender']) \n",
    "            for m in movies \n",
    "            for crew_mem in m['credits']['crew']\n",
    "            if crew_mem['job'] in jobs]\n",
    "    \n",
    "    cursor.executemany(insert_query, actors + crew)\n",
    "    \n",
    "    db.commit()\n",
    "    \n",
    "    return cursor.rowcount"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae20b46c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def populate_movie_person(movies, jobs):\n",
    "    insert_query = \"\"\"\n",
    "    INSERT INTO movie_person\n",
    "    (id_movie, id_person, id_job)\n",
    "    VALUES(%s, %s, %s)\n",
    "    \"\"\"\n",
    "    \n",
    "    movies_actors = [(m['id'], \n",
    "                      actor['id'], \n",
    "                      jobs.index('Actor') + 1)\n",
    "                     for m in movies \n",
    "                     for actor in m['credits']['cast'][0:7]]\n",
    "    \n",
    "    movies_crew = [(m['id'], \n",
    "                    crew_mem['id'], \n",
    "                    jobs.index(crew_mem['job']) + 1) \n",
    "                   for m in movies \n",
    "                   for crew_mem in m['credits']['crew']\n",
    "                   if crew_mem['job'] in jobs]\n",
    "    \n",
    "    cursor.executemany(insert_query, movies_actors + movies_crew)\n",
    "    \n",
    "    db.commit()\n",
    "    \n",
    "    return cursor.rowcount"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62ad3818",
   "metadata": {},
   "outputs": [],
   "source": [
    "def populate_movie_str_comp(str_comps):\n",
    "    \n",
    "    insert_query = \"\"\"\n",
    "    INSERT INTO movie_str_comp\n",
    "    (id_movie, id_str_comp)\n",
    "    VALUES(%s, %s)\n",
    "    \"\"\"\n",
    "    flatrate_es_comps = []\n",
    "    \n",
    "    for str_comp in str_comps:\n",
    "        id_movie = str_comp.get(\"id\")\n",
    "        flatrates = str_comp.get(\"results\", {}).get(\"ES\", {}).get(\"flatrate\", [])\n",
    "        for flatrate in flatrates:\n",
    "            provider_id = flatrate.get(\"provider_id\")\n",
    "            flatrate_es_comps.append((id_movie, provider_id))\n",
    "    \n",
    "    cursor.executemany(insert_query, flatrate_es_comps)\n",
    "    \n",
    "    db.commit()\n",
    "    \n",
    "    return cursor.rowcount"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00287543",
   "metadata": {},
   "outputs": [],
   "source": [
    "jobs = ['Actor', 'Director','Screenplay']\n",
    "\n",
    "# Define the chunk size\n",
    "chunk_size = 1000\n",
    "\n",
    "# Read the JSONL file in chunks\n",
    "for chunk in pd.read_json('data/processed_movies.jsonl', lines=True, chunksize=chunk_size):\n",
    "    # Convert the chunk to a list of dictionaries\n",
    "    movies = chunk.to_dict(orient='records')\n",
    "    \n",
    "    populate_movie(movies)\n",
    "    populate_prod_comp(movies)\n",
    "    populate_movie_prod_comp(movies)\n",
    "    populate_movie_genre(movies)\n",
    "    populate_person(movies, jobs)\n",
    "    populate_movie_person(movies, jobs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ecbc5035",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Define the chunk size\n",
    "chunk_size = 1000\n",
    "\n",
    "for chunk in pd.read_json('data/str_comps.jsonl', lines=True, chunksize=chunk_size):\n",
    "    # Convert the chunk to a list of dictionaries\n",
    "    str_comps = chunk.to_dict(orient='records')\n",
    "    \n",
    "    populate_movie_str_comp(str_comps)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": true,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "357.487px"
   },
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
