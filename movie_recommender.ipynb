{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "bba74bd7",
   "metadata": {},
   "source": [
    "# TFM Final Project <img style=\"display: inline; align-right: 250px; position: absolute; right: 0px;\" src=\"files/Logo-AIT-Red600x-8.webp\" width=\"130\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d0501b5",
   "metadata": {},
   "source": [
    "ðŸ‘‰ Berta Pfaff</br>\n",
    "ðŸ‘‰ Sergio Salvador</br>\n",
    "ðŸ‘‰ Francesc VilarÃ³</br>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1686877",
   "metadata": {},
   "source": [
    "# Project motivation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5294dfc",
   "metadata": {},
   "source": [
    "**Movie recommendation systems have become increasingly popular in recent years** due to the vast amount of movies available for viewers to watch. With the rise of streaming services like Netflix, Hulu, and Amazon Prime, **it has become harder for viewers to decide which movie to watch**, given the plethora of options available.\n",
    "\n",
    "The proposed project aims to **build a movie recommender system using Python, leveraging the TMDB API to fetch movie metadata from 1980 until 2023**. The TMDB (The Movie Database) is an online database that provides comprehensive information related to movies, TV shows, and other forms of visual media. It is a community-driven platform that is curated and maintained by a team of editors and contributors who gather information from various sources, such as film studios, production companies, and fan communities, among others. The TMDB API (Application Programming Interface) provides developers with access to this wealth of data, allowing them to retrieve and use movie and TV show metadata in their own applications and projects.\n",
    "\n",
    "The project will consist of three main parts:\n",
    "\n",
    "1. **Database design**: An Entity-Relationship model (ERM) will be first created, defining the entities, attributes, and relationships that need to be stored in the database. The next step is to create tables that correspond to the entities and attributes identified in the previous step. Each table should contain columns for the various attributes, along with appropriate data types and constraints.\n",
    "\n",
    "\n",
    "2. **Data fetching**: Asynchronous calls to the TMDB API will be used to fetch movie data, such as title, genre, release date, and ratings, among others. Traditional methods such as synchronous API requests would be to slow and inefficient for this aplication. Finally, data will be stored in a mySQL database, allowing for high performance and fast access.\n",
    "\n",
    "\n",
    "3. **EDA (Exploratory Data Analysis)**: Data visualization techniques will be applied to explore and understand the data. Graphs, charts, and histograms will be used to identify trends, patterns, and outliers, which can help improve the model's accuracy and obtain an overall understanding of the movie market in the last 40 years.\n",
    "\n",
    "\n",
    "4. **Recommendation model**: A model will be built using advanced machine learning algorithms. The model will be trained on the movie metadata to generate personalized movie recommendations. the proposed model will utilize a complex algorithm that takes into consideration numerous variables, such as the movie's plot overview, the cast of actors, and the directors involved in its production, among other factors, to ultimately <u>recommend a set of five other movies that share similarities and patterns with the original movie</u>. This comprehensive approach not only provides a reliable and accurate way to suggest new movie options to viewers but also ensures that the recommended movies align with the viewer's preferences and tastes, resulting in a highly personalized and satisfying viewing experience.\n",
    "\n",
    "Overall, this project aims to provide a convenient and personalized movie recommendation system that can help users discover new movies they will enjoy. Additionally, the project will also provide an opportunity to learn and apply several data science techniques learned throughout the master's degree, such as data retrieval, data visualization, and machine learning."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a0ceada",
   "metadata": {},
   "source": [
    "# Imported libraries"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41979533",
   "metadata": {},
   "source": [
    "The following libraries have been used to accomplish the following project:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00323ac4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import mysql.connector\n",
    "import pandas as pd\n",
    "import warnings\n",
    "import requests\n",
    "import time\n",
    "from IPython.display import clear_output\n",
    "import csv\n",
    "from datetime import date, timedelta\n",
    "import ast\n",
    "import asyncio\n",
    "import aiohttp\n",
    "import os\n",
    "import json"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "061cddb2",
   "metadata": {},
   "source": [
    "## Database design"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d5451bb",
   "metadata": {},
   "source": [
    "### Database creation and connection"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b73463b9",
   "metadata": {},
   "source": [
    "Connection to a local mySQL server is established using the 'mysql.connector' library and providing the needed parameters. Finally, a cursor object is instantiated to allow interaction with the database."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48ebb7e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "warnings.filterwarnings(\"ignore\") # Warnings are disabled\n",
    "\n",
    "db = mysql.connector.connect(\n",
    "    host = \"localhost\",\n",
    "    user = \"root\",\n",
    "    password= \"12345\"\n",
    ")\n",
    "\n",
    "cursor = db.cursor()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8cab986f",
   "metadata": {},
   "source": [
    "A new database called 'TMDB' is created and connection to server is established again, this time specifying the 'TMDB' database in the 'database' parameter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0aa5c3ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "cursor.execute(\"CREATE DATABASE TMDB\")\n",
    "db.commit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5fdc6a9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "warnings.filterwarnings(\"ignore\") # Warnings are disabled\n",
    "\n",
    "db = mysql.connector.connect(\n",
    "    host = \"localhost\",\n",
    "    user = \"root\",\n",
    "    password= \"12345\",\n",
    "    database= \"TMDB\"\n",
    ")\n",
    "\n",
    "cursor = db.cursor()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93fa6399",
   "metadata": {},
   "source": [
    "### API schema analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e58f5a69",
   "metadata": {},
   "source": [
    "Before starting to design the structure of the database, an in-depth analysis of the structure and content of the responses that the TMDB API provides is needed, in order to identify the entities, attributes, and relationships that exist in the data model.\n",
    "\n",
    "The TMDB API provides some endpoints of interest to this project:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f9fa75f",
   "metadata": {},
   "source": [
    "#### GET discover/movies"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1cfbed52",
   "metadata": {},
   "source": [
    "The GET discover/movie endpoint in the TMDB API **retrieves a list of movies that match certain criteria**. This endpoint allows users to discover movies by exploring different filtering options, such as release year, genre, language, and more. When making a request to the GET discover/movie endpoint, you can include various query parameters to customize the search criteria. For example, you can specify a minimum or maximum release date, a specific language, or a specific genre ID.\n",
    "\n",
    "The response to a GET discover/movie request includes a list of movies that match the specified criteria, along with metadata such as the movie title, release date, poster image, and more. Each movie in the response is represented as an object with various fields that provide information about the movie.\n",
    "\n",
    "For this project in particular, we need to fetch all movies from 1980 to 2023, so we will be using the following query parameters:\n",
    " - **\"primary_release_date.gte\"**: Allows to obtain movies whose release date is greater than or equal to the input date\n",
    " - **\"primary_release_date.lte\"**: Allows to obtain movies whose release date is lower than or equal to the input date\n",
    " - **\"page\"**: Every request returns only 20 results at a time, so a page parameter is needed to fetch all the results\n",
    " \n",
    " An example of a request using the GET discover/movie endpoint with only one result would be:\n",
    "\n",
    "<img src=\"files/example_GET_discover_movie.png\" style=\"border: 1px solid black;\">\n",
    "\n",
    "We will need more information on each movie than the one provided by the GET discover/movie endpoint, so we will be using this method to fetch only the movie id's from every movie from 1980 to 2023."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "452a6234",
   "metadata": {},
   "source": [
    "#### GET movie details endpoint"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3af7d394",
   "metadata": {},
   "source": [
    "Once we get all the IDs from the movies we can use GET movie/details endpoint in the TMDB API to retrieve all the details of a specific movie identified by its unique movie ID. This endpoint allows you to retrieve comprehensive information about a movie, including its title, overview, release date, runtime, genres, production companies, cast and crew, ratings, posters, trailers, and more.\n",
    "\n",
    "To use this endpoint, you need to provide the movie ID as a path parameter in the URL of the API request. For example, to retrieve the details of the movie \"The Godfather\" (which has a movie ID of 238), you would make a GET request to the following URL:\n",
    "\n",
    "https://api.themoviedb.org/3/movie/238?api_key=YOUR_API_KEY\n",
    "\n",
    "In the response from this endpoint, you will receive a JSON object containing all the available information about the movie, structured according to the TMDB API data model. Following the same example, the requested JSON object for \"The Godfather\" movie would be:\n",
    "\n",
    "<img src=\"files/example_GET_movie_details.png\" style=\"border: 1px solid black;\">\n",
    "\n",
    "Has you can see, the previous request is more complete that the one provided by the GET discover/movie endpoint. Still, no information about the cast and the crew involved in the making of the movie is provided. To obtain this information we will have to use the append_to_response parameter. This parameter allows to include additional information about a movie in the API response, such has cast and crew."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12c245c4",
   "metadata": {},
   "source": [
    "#### GET genre/movie/list endpoint"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c55a34e6",
   "metadata": {},
   "source": [
    "The GET /genre/movie/list endpoint in the TMDB API is used to retrieve a list of all the movie genres available in the TMDB database.\n",
    "\n",
    "When you make a request to this endpoint, you will receive a JSON object containing an array of genre objects, each of which includes the following information:\n",
    "\n",
    "- id: A unique identifier for the genre.\n",
    "- name: The name of the genre.\n",
    "\n",
    "Here is an example response from the GET /genre/movie/list endpoint:\n",
    "\n",
    "<img src=\"files/example_GET_genre_movie_list.png\" style=\"border: 1px solid black;\">\n",
    "\n",
    "You can use the id values returned from this endpoint to filter movies by genre in other TMDB API endpoints, such as the GET discover/movie endpoint, which allows you to search for movies based on various criteria, including genre."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b1b8653",
   "metadata": {},
   "source": [
    "#### GET /watch/providers/movie endpoint"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad4ab1d2",
   "metadata": {},
   "source": [
    "The GET /watch/providers/movie endpoint in the TMDB API is used to retrieve information about all the streaming companies available in the TMDB platform.\n",
    "\n",
    "When you make a request to this endpoint, you can include the watch_region parameter to specify the ISO 3166-1 code for the region you're interested in.\n",
    "\n",
    "The response to this request will include an object containing the following information:\n",
    "\n",
    "\n",
    "- results: An array of provider objects, each of which includes the following information:\n",
    " - display_priority: The display priority of the provider for the movie in the specified region.\n",
    " - logo_path: The path to the logo image for the provider.\n",
    " - provider_name: The name of the streaming provider.\n",
    " - provider_id: The ID of the streaming provider.\n",
    "\n",
    "For example, to retrieve all the movie providers in Spain, we would make a GET request to the following URL\n",
    "\n",
    "https://api.themoviedb.org/3/watch/providers/movie?api_key=YOUR_API_KEY&watch_region=ES\n",
    "\n",
    "Which would return the following response:\n",
    "\n",
    "<img src=\"files/example_GET_watch_providers_movie.png\" style=\"border: 1px solid black;\">\n",
    "\n",
    "Please note that a portion of the response above has been ommited to avoid overwhelming the screen with excessive information."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7442345c",
   "metadata": {},
   "source": [
    "## GET movie providers"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "780f5462",
   "metadata": {},
   "source": [
    "Since the append_to_response parameter in the GET movie details endpoint doesn't support watch providers, we have to fetch them separately using GET watch providers.\n",
    "\n",
    "The GET watch providers method is a function of the TMDB API that allows you to retrieve a list of streaming providers for a specific movie. This method provides information about where you can watch a particular title, along with links to the corresponding streaming service.\n",
    "\n",
    "To use this method, you need to make a GET request to the following endpoint:\n",
    "\n",
    "https://api.themoviedb.org/3/movie/{movie_id}/watch/providers?api_key=YOUR_API_KEY\n",
    "\n",
    "To use this endpoint, you need to provide the movie ID as a path parameter in the URL of the API request. For example, to retrieve the watch providers for the movie \"The Godfather\" (which has a movie ID of 238), you would make a GET request to the following URL:\n",
    "\n",
    "https://api.themoviedb.org/3/movie/238/watch/providers?api_key=YOUR_API_KEY\n",
    "\n",
    "In the response from this endpoint, you will receive a JSON object containing all the available information about the available watch providers. Following the same example, the requested JSON object for \"The Godfather\" movie would be:\n",
    "\n",
    "\n",
    "<img src=\"files/example_GET_watch_providers.png\" style=\"border: 1px solid black; width:800px\">\n",
    "\n",
    "Please note that a portion of the response above has been ommited to avoid overwhelming the screen with excessive information."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fbe725c3",
   "metadata": {},
   "source": [
    "### Entity-Relationship model (ERM)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e523471",
   "metadata": {},
   "source": [
    "An ERM model is firstly defined to represent the entities and relationships of the database. \n",
    "\n",
    "The database will consist of the following main tables:\n",
    "\n",
    "- **movie_ table**: The main table. This table will store the data unique to every movie, such as title, overview or runtime.\n",
    "- **str_comp_ table**: Stores all the flatrate streaming companies available in Spain\n",
    "- **prod_comp table**: Stores all the production companies\n",
    "- **genre table**: Stores all the available genres in the TMDB platform\n",
    "- **person table**: Stores the main crew and cast that have been involved in the movies of the database.\n",
    "- **jobs table**: Stores the jobs that will be considered for adding a person to the database. In this case, only roles of actor, director and screenplay have been considered.\n",
    "\n",
    "Junction tables (red tables on the ERM diagram) are needed to avoid many-to-many relationships between the main table and every other table. For instance, for a particular movie, there can be various streaming companies and a particular streaming company can stream various movies. This kind of relationship is impossible to represent in a structured database such as SQL, so a middle table is created to relate both tables using foreign keys.\n",
    "\n",
    "The meaning of each attribute for each table will be explained as we create them, so as not to clutter this Jupyter cell with too much text."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef2c6c18",
   "metadata": {},
   "source": [
    "<img src=\"files/DB_ERM_v2.png\" style=\"width:700px\">"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a172817",
   "metadata": {},
   "source": [
    "### Table creation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d2bf112",
   "metadata": {},
   "source": [
    "Next, all tables in our mySQL database have to be created before being populated."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "690c6444",
   "metadata": {},
   "source": [
    "#### movie table creation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b4073f6",
   "metadata": {},
   "source": [
    "This is the main table. Consists of the following columns:\n",
    "- **id_movie**: Movie unique identifier provided by TMDB API\n",
    "- **original_title**: Movie title maintaining original alphabet\n",
    "- **overview**: Brief summary of the movie's plot\n",
    "- **popularity**: Value atributed by the TMDB platform based on multiple factors to indicate the level of interest and attention that the movie is receiving from the public.\n",
    "- **poster_path**: Endpoint to the movie's poster image\n",
    "- **release_date**: Date of the primary release of the movie given in the format YYYY-MM-DD\n",
    "- **title**: Movie title translated to english\n",
    "- **vote_average**: Average vote given by TMDB users\n",
    "- **vote_count**: Number of votes\n",
    "- **budget**: Total cost of movie production\n",
    "- **revenue**: Total amount of money that the movie has generated given in american dollars \n",
    "- **runtime**: total duration of the movie given in minutes\n",
    "\n",
    "All of the data needed to populate this table can be obtained using the GET movie details endpoint explained above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "710b1a2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "query_movie = \"\"\"\n",
    "    CREATE TABLE movie(\n",
    "        id_movie int,\n",
    "        original_title varchar(300),\n",
    "        original_language varchar(20), \n",
    "        overview varchar(1000),\n",
    "        popularity float,\n",
    "        poster_path varchar(200),\n",
    "        release_date varchar(20),\n",
    "        title varchar(300),\n",
    "        vote_average float,\n",
    "        vote_count int,\n",
    "        budget int, \n",
    "        revenue bigint,\n",
    "        runtime int,\n",
    "        PRIMARY KEY (id_movie)\n",
    "    )\n",
    "\"\"\"\n",
    "\n",
    "cursor.execute(query_movie)\n",
    "db.commit()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e72c3db",
   "metadata": {},
   "source": [
    "#### Streaming companies"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d1f80e3",
   "metadata": {},
   "source": [
    "All tables related to the streaming companies are created simultaneously:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7873f80b",
   "metadata": {},
   "source": [
    "##### str_comp table creation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3cd17d8a",
   "metadata": {},
   "source": [
    "This table stores all unique streaming companies available in our dataset. Consists of two columns:\n",
    "\n",
    "- **id_str_comp**: Autoincremental ID given to every unique streaming company. This ID is not provided by the TMDB API\n",
    "- **name**: Streaming company name (e.g. Netflix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1f5777a",
   "metadata": {},
   "outputs": [],
   "source": [
    "query_str_comp = \"\"\"\n",
    "    CREATE TABLE str_comp (\n",
    "    id_str_comp int AUTO_INCREMENT,\n",
    "    name varchar(50),\n",
    "    PRIMARY KEY (id_str_comp)\n",
    ")\n",
    "\"\"\"\n",
    "\n",
    "cursor.execute(query_str_comp)\n",
    "db.commit()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf884840",
   "metadata": {},
   "source": [
    "##### movie_str_comp junction table creation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1afe8ce",
   "metadata": {},
   "source": [
    "This junction table is created to represent a many-to-many relationship between movies and streaming companies in our SQL database.\n",
    "\n",
    "Each record in the \"movie_str_comp\" table represents a unique combination of a movie and a streaming company or studio, and the \"id_movie\" and \"id_str_comp\" columns store the foreign keys that reference the primary keys of the \"movie\" and \"str_comp\" tables, respectively.\n",
    "\n",
    "Consists of the following columns:\n",
    "\n",
    "- **id_mov_str_comp**: This is a unique identifier for each record in the junction table, and is set to auto-increment.\n",
    "\n",
    "- **id_movie**: Stores the foreign key of the \"movie\" table, which is used to link the junction table to the \"movie\" table.\n",
    "\n",
    "- **id_str_comp**: Stores the foreign key of the \"str_comp\" table, which is used to link the junction table to the \"str_comp\" table."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "518c9ac4",
   "metadata": {},
   "outputs": [],
   "source": [
    "query_movie_str_comp = \"\"\"\n",
    "    CREATE TABLE movie_str_comp (\n",
    "    id_mov_str_comp int AUTO_INCREMENT,\n",
    "    id_movie int,\n",
    "    id_str_comp int,\n",
    "    PRIMARY KEY (id_mov_str_comp),\n",
    "    FOREIGN KEY (id_movie) REFERENCES movie(id_movie),\n",
    "    FOREIGN KEY (id_str_comp) REFERENCES str_comp(id_str_comp)\n",
    ")\n",
    "\"\"\"\n",
    "\n",
    "cursor.execute(query_movie_str_comp)\n",
    "db.commit()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8e15bd3",
   "metadata": {},
   "source": [
    "#### Production companies"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49909e64",
   "metadata": {},
   "source": [
    "All tables related to the streaming companies are created simultaneously:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1eb91f49",
   "metadata": {},
   "source": [
    "##### prod_comp table creation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2fa4da96",
   "metadata": {},
   "source": [
    "This table stores all unique production companies available in our dataset. Consists of three columns:\n",
    "\n",
    "- **id_prod_comp**: ID given to every unique production company. This ID is provided by the TMDB API\n",
    "- **name**: Production company name (e.g. Paramount)\n",
    "- **origin_country**: Country of origin of the production company, based on the ISO 3166-1 standard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad43874b",
   "metadata": {},
   "outputs": [],
   "source": [
    "query_prod_comp = \"\"\"\n",
    "    CREATE TABLE prod_comp ( \n",
    "         id_prod_comp int NOT NULL,\n",
    "         name varchar (100),\n",
    "         origin_country varchar (20),\n",
    "\n",
    "         PRIMARY KEY (id_prod_comp)\n",
    "      )\n",
    "\"\"\"\n",
    "cursor.execute(query_prod_comp)\n",
    "db.commit()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39ce4afc",
   "metadata": {},
   "source": [
    "##### movie_prod_comp junction table creation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd08ff24",
   "metadata": {},
   "source": [
    "This junction table is created to represent a many-to-many relationship between movies and production companies or studios in our SQL database.\n",
    "\n",
    "Each record in the \"movie_str_comp\" table represents a unique combination of a movie and a production company or studio, and the \"id_movie\" and \"id_prod_comp\" columns store the foreign keys that reference the primary keys of the \"movie\" and \"prod_comp\" tables, respectively.\n",
    "\n",
    "Consists of the following columns:\n",
    "\n",
    "- **id_mov_prod_comp**: This is a unique identifier for each record in the junction table, and is set to auto-increment.\n",
    "\n",
    "- **id_movie**: Stores the foreign key of the \"movie\" table, which is used to link the junction table to the \"movie\" table.\n",
    "\n",
    "- **id_prod_comp**: Stores the foreign key of the \"prod_comp\" table, which is used to link the junction table to the \"prod_comp\" table."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d787677d",
   "metadata": {},
   "outputs": [],
   "source": [
    "query_movie_prod_comp = \"\"\"\n",
    "    CREATE TABLE movie_prod_comp (\n",
    "        id_mov_prod_comp int AUTO_INCREMENT,\n",
    "        id_movie int,\n",
    "        id_prod_comp int,\n",
    "        \n",
    "        PRIMARY KEY (id_mov_prod_comp),\n",
    "        FOREIGN KEY (id_movie) REFERENCES movie(id_movie),\n",
    "        FOREIGN KEY (id_prod_comp) REFERENCES prod_comp(id_prod_comp)\n",
    "      )\n",
    "\"\"\"\n",
    "cursor.execute(query_movie_prod_comp)\n",
    "db.commit()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "763cb12d",
   "metadata": {},
   "source": [
    "#### Genres"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6bad161b",
   "metadata": {},
   "source": [
    "All tables related to the streaming companies are created simultaneously:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63debe16",
   "metadata": {},
   "source": [
    "##### genre table creation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd96a7c4",
   "metadata": {},
   "source": [
    "This table stores all unique movie genres available in our dataset. Consists of two columns:\n",
    "\n",
    "- **id_genre**: ID given to every unique movie genre. This ID is provided by the TMDB API\n",
    "- **genre**: Name of the genre (e.g. Comedy) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76b74deb",
   "metadata": {},
   "outputs": [],
   "source": [
    "query_genre = \"\"\"\n",
    "    CREATE TABLE genre ( \n",
    "         id_genre int NOT NULL,\n",
    "         genre varchar (30),\n",
    "\n",
    "         PRIMARY KEY(id_genre)\n",
    "      )\n",
    "\"\"\"\n",
    "cursor.execute(query_genre)\n",
    "db.commit()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ed41106",
   "metadata": {},
   "source": [
    "##### movie_genre table creation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "033888a9",
   "metadata": {},
   "source": [
    "This junction table is created to represent a many-to-many relationship between movies and genres in our SQL database.\n",
    "\n",
    "Each record in the \"movie_genre\" table represents a unique combination of a movie and a genre, and the \"id_movie\" and \"id_genre\" columns store the foreign keys that reference the primary keys of the \"movie\" and \"genre\" tables, respectively.\n",
    "\n",
    "Consists of the following columns:\n",
    "\n",
    "- **id_mov_genre**: This is a unique identifier for each record in the junction table, and is set to auto-increment.\n",
    "\n",
    "- **id_movie**: Stores the foreign key of the \"movie\" table, which is used to link the junction table to the \"movie\" table.\n",
    "\n",
    "- **id_genre**: Stores the foreign key of the \"genre\" table, which is used to link the junction table to the \"genre\" table."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "785e1eec",
   "metadata": {},
   "outputs": [],
   "source": [
    "query_movie_genre = \"\"\"\n",
    "    CREATE TABLE movie_genre (\n",
    "        id_mov_genre int AUTO_INCREMENT,\n",
    "        id_movie int,\n",
    "        id_genre int,\n",
    "\n",
    "        PRIMARY KEY (id_mov_genre),\n",
    "        FOREIGN KEY (id_movie) REFERENCES movie(id_movie),\n",
    "        FOREIGN KEY (id_genre) REFERENCES genre(id_genre)\n",
    "      )\n",
    "\"\"\"\n",
    "cursor.execute(query_movie_genre)\n",
    "db.commit()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bee441bb",
   "metadata": {},
   "source": [
    "#### People"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5fae787f",
   "metadata": {},
   "source": [
    "All tables related to people are created simultaneously. A person can be an actor or someone from the crew, for example, a director"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7bc5787",
   "metadata": {},
   "source": [
    "##### _person_ table creation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1dd71aa7",
   "metadata": {},
   "source": [
    "This table stores all people available in our dataset. Consists of three columns:\n",
    "\n",
    "- **id_person**: ID given to every unique movie genre. This ID is provided by the TMDB API\n",
    "- **name**: Name of the person (e.g. Brad Pitt)\n",
    "- **gender**: Binary column. Can adopt two values: 1 (Female) and 2 (Male)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "874a0313",
   "metadata": {},
   "outputs": [],
   "source": [
    "query_person = \"\"\"\n",
    "    CREATE TABLE person ( \n",
    "         id_person int NOT NULL,\n",
    "         name varchar (50),\n",
    "         gender int,\n",
    "\n",
    "         PRIMARY KEY (id_person)\n",
    "      )\n",
    "\"\"\"\n",
    "cursor.execute(query_person)\n",
    "db.commit()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27a52eac",
   "metadata": {},
   "source": [
    "##### job table creation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4fe2e6d3",
   "metadata": {},
   "source": [
    "This table stores the jobs of the people (crew and cast) involved in the movies. For this project we have only considered three jobs: Actor, Director and Screenplay. Although the production of a movie involves many more jobs, we have omitted some from our project to keep it manageable.\n",
    "\n",
    "This table consists of two columns:\n",
    "\n",
    "- **id_job**: ID given to every job. This ID is not provided by the TMDB API\n",
    "- **job_name**: Name of the job (e.g. Actor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1445d87a",
   "metadata": {},
   "outputs": [],
   "source": [
    "query_job = \"\"\"\n",
    "    CREATE TABLE job (\n",
    "        id_job int AUTO_INCREMENT,\n",
    "        job_name varchar(50),\n",
    "        \n",
    "        PRIMARY KEY (id_job)\n",
    "      )\n",
    "\"\"\"\n",
    "cursor.execute(query_job)\n",
    "db.commit()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ff1dbc1",
   "metadata": {},
   "source": [
    "##### movie_person junction table creation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7888c51a",
   "metadata": {},
   "source": [
    "This junction table is created to represent a many-to-many relationship between movies and people in our SQL database.\n",
    "\n",
    "Each record in the \"movie_person\" table represents a unique combination of a movie and a person, and the \"id_movie\" and \"id_person\" columns store the foreign keys that reference the primary keys of the \"movie\" and \"person\" tables, respectively.\n",
    "\n",
    "Consists of the following columns:\n",
    "\n",
    "- **id_mov_person**: This is a unique identifier for each record in the junction table, and is set to auto-increment.\n",
    "\n",
    "- **id_movie**: Stores the foreign key of the \"movie\" table, which is used to link the junction table to the \"movie\" table.\n",
    "\n",
    "- **id_person**: Stores the foreign key of the \"person\" table, which is used to link the junction table to the \"person\" table.\n",
    "\n",
    "- **id_job**: Stores the foreign key of the \"job\" table, which is used to link the junction table to the \"job\" table."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67a42cbd",
   "metadata": {},
   "outputs": [],
   "source": [
    "query_movie_person = \"\"\"\n",
    "    CREATE TABLE movie_person ( \n",
    "         id_mov_person int AUTO_INCREMENT,\n",
    "         id_movie int,\n",
    "         id_person int,\n",
    "         id_job int,\n",
    "\n",
    "         PRIMARY KEY (id_mov_person),\n",
    "         FOREIGN KEY (id_movie) REFERENCES movie(id_movie),\n",
    "         FOREIGN KEY (id_person) REFERENCES person(id_person),\n",
    "         FOREIGN KEY (id_job) REFERENCES job(id_job)\n",
    "      )\n",
    "\"\"\"\n",
    "cursor.execute(query_movie_person)\n",
    "db.commit()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74ec106d",
   "metadata": {},
   "source": [
    "## Data fetching"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c559c02",
   "metadata": {},
   "source": [
    "To register for an TMDB API key, you must first login into TMDB webpage and then click the API link from within your account settings page. \n",
    "\n",
    "The API key used throughout this project is the following (keep in mind that this API key is personal and that you should generate your own API key):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42025516",
   "metadata": {},
   "outputs": [],
   "source": [
    "api_key = \"ac6862efab2ddf803567630c9f474ab8\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b96a2a6b",
   "metadata": {},
   "source": [
    "### Independent tables generation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b654e143",
   "metadata": {},
   "source": [
    "Some of the tables in our database (specifically the genres, streaming companies and jobs tables) have to be populated separately, since they use diferent API request endpoints to fetch the information."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6551e631",
   "metadata": {},
   "source": [
    "#### Genres table"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7bab77c",
   "metadata": {},
   "source": [
    "To fetch the genres information, we need to use the following request URL and query parameters:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd67c66c",
   "metadata": {},
   "outputs": [],
   "source": [
    "url_genres = \"https://api.themoviedb.org/3/genre/movie/list\"\n",
    "\n",
    "query_params = {\n",
    "                \"api_key\": api_key,\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d535730d",
   "metadata": {},
   "source": [
    "We define the a function to get all the genres available in the TMDB API:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4406a8a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_genres(url_genres, query_params):\n",
    "    \"\"\"\n",
    "    This function, given a request URL and query parameters, sends a request to the TMDB API and returns a list of tuples \n",
    "    containing the id and name of all the available genres.\n",
    "    \"\"\"\n",
    "    # The request is made to the API using the requests library\n",
    "    response = requests.get(url_genres, query_params).json()\n",
    "    \n",
    "    # ID and name are then filtered and appended to a list using list comprehension\n",
    "    genres = [(genre['id'], genre['name']) for genre in response['genres']]\n",
    "    \n",
    "    return genres"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9efbd4b6",
   "metadata": {},
   "source": [
    "If we show the first available genre, we obtain the following tupple, where the first element is the genre's id and the second element is the genre's name:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6094ef4",
   "metadata": {},
   "outputs": [],
   "source": [
    "genres = get_genres(url_genres, query_params)\n",
    "genres[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c6eedf6",
   "metadata": {},
   "source": [
    "Having fetched all of the genres available in the TMDB platform, we can now define a function to populate the 'genre' table:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54041e7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def populate_genre(genres):\n",
    "    \"\"\"\n",
    "    This function takes a list of tupples of movie genres and populates a table called 'genre' in a SQL database.\n",
    "    Each tupple has two elements: genre ID and genre name.\n",
    "    \"\"\"\n",
    "    # An insert query is defined to populate the genre table\n",
    "    insert_query = \"\"\"\n",
    "    INSERT INTO genre\n",
    "    (id_genre, genre)\n",
    "    VALUES(%s, %s)\n",
    "    \"\"\"\n",
    "    \n",
    "    # Since we have a list of tupples, we can populate the 'genre' table all at once by using the executemany method\n",
    "    cursor.executemany(insert_query, genres)\n",
    "    db.commit()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5922a608",
   "metadata": {},
   "source": [
    "We finally populate the 'genre' table by calling populate_genre() and passing the fetched genres as a parameter:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0bb4c64b",
   "metadata": {},
   "outputs": [],
   "source": [
    "populate_genre(genres)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a79926ef",
   "metadata": {},
   "source": [
    "After populating 'genre', the table looks like this:\n",
    "\n",
    "<img src=\"files/populated_genre_table.png\" style=\"border: 1px solid black; width: 200px\">\n",
    "\n",
    "Keep in mind that only a portion of the table is shown in the image above, since it as a large amount of rows and would be unmanageable to show them all on screen."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a3fb00f",
   "metadata": {},
   "source": [
    "#### Streaming Companies table"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62c17620",
   "metadata": {},
   "source": [
    "To fetch the streaming companies information, we need to use the following request URL and query parameters.\n",
    "\n",
    "We use the watch_region parameter set to \"ES\", since we only want to obtain the streaming companies that operate in Spain."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60f1aaae",
   "metadata": {},
   "outputs": [],
   "source": [
    "url_str_comps = \"https://api.themoviedb.org/3/watch/providers/movie\"\n",
    "\n",
    "query_params_str_comps = {\n",
    "                \"api_key\": api_key,\n",
    "                \"watch-region\": \"ES\"\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ffb44555",
   "metadata": {},
   "source": [
    "We define the a function to get all the streaming companies available in the TMDB API:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dee6a5b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_str_comps(url_str_comps, query_params_str_comp):\n",
    "    \"\"\"\n",
    "    This function sends a request to the TMDB API and returns a list of tuples \n",
    "    containing the ID and name of all the available streaming companies. \n",
    "    \"\"\"\n",
    "    \n",
    "    # Request is made using the 'requests' library\n",
    "    response = requests.get(url_str_comps, query_params_str_comps).json()\n",
    "    \n",
    "    # ID and name are stored for every streaming company using list comprehension\n",
    "    str_comps = [(result['provider_id'], result['provider_name']) for result in response['results']]\n",
    "    \n",
    "    return str_comps"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "422e8d49",
   "metadata": {},
   "source": [
    "If we show the first available streaming company, we obtain the following tupple, where the first element is the streaming company id and the second element is the streaming company name:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "361f542e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "str_comps = get_str_comps(url_str_comps, query_params_str_comps)\n",
    "str_comps[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c564768c",
   "metadata": {},
   "source": [
    "Having fetched all of the genres available in the TMDB platform, we can now define a function to populate the 'genre' table:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "794ebea4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def populate_str_comps(str_comps):\n",
    "    \"\"\"\n",
    "    This function takes a list of tupples of streaming companies and populates a table called 'str_comp' in a SQL database.\n",
    "    Each tupple has two elements: streaming company ID and name.\n",
    "    \"\"\"\n",
    "    \n",
    "    # An insert query is defined to populate the 'str_comp' table\n",
    "    insert_query = \"\"\"\n",
    "    INSERT INTO str_comp\n",
    "    (id_str_comp, name)\n",
    "    VALUES(%s, %s)\n",
    "    \"\"\"\n",
    "    \n",
    "    # Since we have a list of tupples, we can populate the 'str_comps' table all at once by using the executemany method\n",
    "    cursor.executemany(insert_query, str_comps)\n",
    "    db.commit()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "275bb114",
   "metadata": {},
   "source": [
    "We finally populate the 'str_comp' table by calling populate_str_comps() and passing the fetched streaming companies as a parameter:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9d60989",
   "metadata": {},
   "outputs": [],
   "source": [
    "populate_str_comps(str_comps)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2360ee0",
   "metadata": {},
   "source": [
    "After populating 'genre', the table looks like this:\n",
    "\n",
    "<img src=\"files/populated_str_comp_table.png\" style=\"border: 1px solid black; width: 200px\">\n",
    "\n",
    "Keep in mind that only a portion of the table is shown in the image above, since it as a large amount of rows and would be unmanageable to show them all on screen."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e065abc7",
   "metadata": {},
   "source": [
    "#### Jobs table "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f49efc36",
   "metadata": {},
   "source": [
    "We define three major roles to be fetched from the TMDB database. This is completely scalable and more roles could be included in future versions of this project."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93181799",
   "metadata": {},
   "outputs": [],
   "source": [
    "jobs = ['Actor', 'Director','Screenplay']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2c18b37",
   "metadata": {},
   "source": [
    "The jobs defined above are inserted into the database through the following function:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb55797c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def populate_job(jobs):\n",
    "    \"\"\"\n",
    "    This function takes a list of tupples of jobs and populates a table called 'job' in a SQL database.\n",
    "    Each tupple has two elements: job ID and job name.\n",
    "    \"\"\"\n",
    "    \n",
    "    # An insert query is defined to populate the 'job' table\n",
    "    insert_query = \"\"\"\n",
    "    INSERT INTO job\n",
    "    (job_name)\n",
    "    VALUES(%s)\n",
    "    \"\"\"\n",
    "    # Jobs are introduced one by one into the SQL database using the execute method\n",
    "    for job in jobs:\n",
    "        cursor.execute(insert_query, [job])\n",
    "    db.commit()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e75f189f",
   "metadata": {},
   "source": [
    "'jobs' table is populated by calling populate_job() and passing the jobs list as a parameter:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3c0eaed",
   "metadata": {},
   "outputs": [],
   "source": [
    "populate_job(jobs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08520d84",
   "metadata": {},
   "source": [
    "After populating 'job', the table looks like this:\n",
    "\n",
    "<img src=\"files/populated_job_table.png\" style=\"border: 1px solid black; width: 200px\">"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e1cecc1",
   "metadata": {},
   "source": [
    "### Movies IDs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e981e8a8",
   "metadata": {},
   "source": [
    "Since all tables are created and the independent tables have been populated, we can now begin to fetch the movies IDs by using the GET discover/movie endpoint.\n",
    "\n",
    "Let's first define some needed parameters:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32840434",
   "metadata": {},
   "outputs": [],
   "source": [
    "# We define the range of years we want to fetch from the TMDB database\n",
    "start_year = 1980\n",
    "end_year = 1980\n",
    "\n",
    "# GET discover/movie endpoint\n",
    "url_discover = \"https://api.themoviedb.org/3/discover/movie\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e81faf81",
   "metadata": {},
   "source": [
    "#### Parameter generation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "224b5c3b",
   "metadata": {},
   "source": [
    "Since the TMDB API only returns 20 results per page and a maximum of 500 pages, we decided to make the requests month by month for every year in the range (start_year, end_year). To do this, we will pass the first and last day of every month as a request parameter.\n",
    "\n",
    "Given a start year and an end year, we can easily obtain the first and last day of every month through the following function:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ee91fb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def month_range_dict(start_year, end_year):\n",
    "    \"\"\"\n",
    "    Returns a dictionary that maps the first day of a month to the last day of the month, given a start and end year.\n",
    "    \"\"\"\n",
    "    \n",
    "    # The dictionary that will map the first day to the last day of a month is initialized\n",
    "    month_range = {}\n",
    "    \n",
    "    # We obtain the first day of the start year and the last day of the end year and pass it to date format\n",
    "    start_date = date(start_year, 1, 1)\n",
    "    end_date = date(end_year, 12, 31)\n",
    "\n",
    "    # Iterate over all months between start and end dates\n",
    "    while start_date < end_date:\n",
    "        \n",
    "        # Year and month are fetched\n",
    "        year = start_date.year\n",
    "        month = start_date.month\n",
    "        \n",
    "        # The last day of the month is obtained\n",
    "        last_day = (date(year, month, 1) + timedelta(days=32)).replace(day=1) - timedelta(days=1)\n",
    "        \n",
    "        # First and last date of the month are stored in a dictionary\n",
    "        month_range[start_date.strftime('%Y-%m-%d')] = last_day.strftime('%Y-%m-%d')\n",
    "        \n",
    "        # start_date is updated\n",
    "        start_date = last_day + timedelta(days=1)\n",
    "\n",
    "    return month_range"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55fd2222",
   "metadata": {},
   "source": [
    "We also need to know how many pages every period of time has, so we can know the amount of requests that we have to make. We obtain this value by fetching the value of the key 'total_pages' that is present in every request."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bfb9f220",
   "metadata": {},
   "outputs": [],
   "source": [
    "def total_pages(start_date, end_date, api_key, url_discover):\n",
    "    \n",
    "    # Query parameters structure is defined. Page is set to max just for convinience  \n",
    "    param = {'api_key': api_key,\n",
    "             'primary_release_date.gte': start_date,\n",
    "             'primary_release_date.lte': end_date,\n",
    "             'page': 500}\n",
    "    \n",
    "    # Request is made, and 'total_pages' value is returned\n",
    "    return requests.get(url_discover, param).json()['total_pages']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "234f9e04",
   "metadata": {},
   "source": [
    "As an example, we obtain the total amount of pages between the first day of 1980 and the last day of 2023:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d1e5e50",
   "metadata": {},
   "outputs": [],
   "source": [
    "total_pages('1980-01-01', '2023-12-31', api_key, url_discover)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03d969b4",
   "metadata": {},
   "source": [
    "We can now define a function to obtain query parameters for each month in the range start_year-end_year by using the month_range_dict() and total_pages() functions defined above"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0bdf29ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "def params_generator(start_year, end_year, api_key, url_discover):\n",
    "    \n",
    "    # Variables are initialized\n",
    "    params = []\n",
    "    total_pag = 0\n",
    "    \n",
    "    # We iterate through the start and end of every month inside of the range start_year-end_year\n",
    "    for start_date, end_date in month_range_dict(start_year, end_year).items():\n",
    "        \n",
    "        # Total number of pages of the request is fetched and stored\n",
    "        total_pag = total_pages(start_date, end_date, api_key, url_discover)\n",
    "        \n",
    "        page = 1\n",
    "        \n",
    "        # Query parameters are generated until we reach the total number of pages\n",
    "        while page <= total_pag:\n",
    "            params.append({\n",
    "                \"api_key\": api_key,\n",
    "                \"primary_release_date.gte\": start_date,\n",
    "                \"primary_release_date.lte\": end_date,\n",
    "                \"page\": page\n",
    "            })\n",
    "            page += 1\n",
    "            \n",
    "    # We check if there is a directory called 'data' in the working directory. If it doesn't exist, we create it\n",
    "    # This is the directory where we will store all of the obtained query parameters\n",
    "    if not os.path.exists('data'):\n",
    "        os.makedirs('data')\n",
    "        \n",
    "    fieldnames = ['api_key', 'primary_release_date.gte', 'primary_release_date.lte', 'page']\n",
    "    \n",
    "    # Parameters are then stored in an external csv file for later use\n",
    "    with open(f'data/discover_params_{start_year}_{end_year}.csv', 'w', newline='') as csvfile:\n",
    "        writer = csv.DictWriter(csvfile, fieldnames=fieldnames)\n",
    "        writer.writeheader()\n",
    "        for param in params:\n",
    "            writer.writerow(param)\n",
    "        \n",
    "    return params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e43e1e30",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "params = params_generator(start_year, end_year, api_key, url_discover)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e5e0c71",
   "metadata": {},
   "source": [
    "Here is an example of what the query parameters for the first months of 1980 would look like:\n",
    "\n",
    "<img src=\"files/example_discover_movie_params2.png\" style=\"border: 1px solid black\">"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e51c32a",
   "metadata": {},
   "source": [
    "After storing the query parameters in an external csv file, we need a function to read that csv file and extract the data contained in it:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d39272b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_discover_params_csv(csv_filepath):\n",
    "    json_list = []\n",
    "    with open(csv_filepath, 'r', newline='') as csvfile:\n",
    "        reader = csv.DictReader(csvfile)\n",
    "        for row in reader:\n",
    "            json_list.append(row)\n",
    "    return json_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a1effa4",
   "metadata": {},
   "outputs": [],
   "source": [
    "params = read_discover_params_csv(f'data/discover_params_{start_year}_{end_year}.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da1b67e2",
   "metadata": {},
   "source": [
    "#### Asynchronous API call"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bfbc1901",
   "metadata": {},
   "source": [
    "Since we have to make a lot of requests to the TMDB API, a traditional aproach such as using the requests library would take to long to fetch all the results. Given that, we decide to do asynchronous API calls. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0555b6af",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_tasks_discover(session, url, params, processed_pages):\n",
    "    tasks = []\n",
    "    for i, param in enumerate(params):\n",
    "        if processed_pages[i] == 0:\n",
    "            tasks.append((i, session.get(url, params=param, timeout = 15)))\n",
    "    return tasks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e81d3d4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "async def discover_api_call(url, params, processed_pages, max_tries=3):\n",
    "    results=[]\n",
    "    exceptions = []\n",
    "    page_counter = 0\n",
    "    try_counter = 0\n",
    "    max_step = 1000\n",
    "    step = max_step\n",
    "    while try_counter < max_tries:\n",
    "        async with aiohttp.ClientSession() as session:\n",
    "            tasks = get_tasks_discover(session, url, params, processed_pages)\n",
    "            if not tasks:\n",
    "                return results, exceptions\n",
    "            if len(tasks) < max_step:\n",
    "                step = len(tasks)\n",
    "            for i in range(0, len(tasks), step): #len(tasks)\n",
    "                batch = tasks[i:i+step]\n",
    "                responses = await asyncio.gather(*[t[1] for t in batch], return_exceptions=True)\n",
    "                #await asyncio.sleep()\n",
    "                for j, response in enumerate(responses):\n",
    "                    try:\n",
    "                        movies_page = await response.json()\n",
    "                        results.append(movies_page['results'])\n",
    "                        processed_pages[batch[j][0]] = 1\n",
    "                        page_counter += 1\n",
    "                        clear_output(wait=True)\n",
    "                        print(f'{page_counter} pages out of {len(params)} have been fetched')\n",
    "                    except:\n",
    "                        exceptions.append(response)\n",
    "        try_counter += 1\n",
    "    return results, exceptions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2521e28b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "start = time.monotonic()\n",
    "discovered_movies, exceptions = await discover_api_call(url_discover, params, processed_pages)\n",
    "end = time.monotonic()\n",
    "\n",
    "print(f'Elapsed time: {round(end - start, 2)} seconds')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea282f9b",
   "metadata": {},
   "source": [
    "After having fetched all movies from 1980 to 2023 with the GET discover/movie method, we can now extract the IDs of the movies and store them in an external csv file:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d69d871b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_movie_ids(discovered_movies):\n",
    "    \n",
    "    if not os.path.exists('data'):\n",
    "        os.makedirs('data')\n",
    "    \n",
    "    movie_ids = {movie['id']: 0\n",
    "            for page in discovered_movies\n",
    "            for movie in page}\n",
    "    \n",
    "    with open(f'data/ids_movies_{start_year}-{end_year}.csv', 'w') as f:\n",
    "        for key in movie_ids.keys():\n",
    "            f.write(\"%s,%s\\n\"%(key,movie_ids[key]))\n",
    "            \n",
    "    print(f'{len(movie_ids)} movie IDs have been saved succesfully')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "089d9890",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "get_movie_ids(discovered_movies)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70224d43",
   "metadata": {},
   "source": [
    "After storing the movie IDs in an external csv file, we need a function to read that csv file and extract the data contained in it:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "393c2dfc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def csv_to_dict(filepath):\n",
    "    # create an empty dictionary to store the CSV data\n",
    "    csv_dict = {}\n",
    "\n",
    "    # open the CSV file in read mode\n",
    "    with open(filepath, 'r') as f:\n",
    "\n",
    "    # create a reader object to read the CSV data\n",
    "        reader = csv.reader(f)\n",
    "\n",
    "    # loop through each row in the CSV file\n",
    "        for row in reader:\n",
    "            csv_dict[row[0]] = ast.literal_eval(row[1])\n",
    "\n",
    "    return csv_dict"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "643db229",
   "metadata": {},
   "source": [
    "### Movie details"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d448acb",
   "metadata": {},
   "source": [
    "Having all movie IDs stored in an external file, we can now use the GET movie details endpoint to fetch all the available metadata for each movie in the TMDB database.\n",
    "\n",
    "Let's define the following parameters:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15e7a5a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "url_details = \"https://api.themoviedb.org/3/movie/\"\n",
    "\n",
    "details_params = {\n",
    "                \"api_key\": \"ac6862efab2ddf803567630c9f474ab8\",\n",
    "                \"append_to_response\": \"credits\"\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9104386",
   "metadata": {},
   "source": [
    "We read the movie IDs we had previously stored in an external file:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e072ac8e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "ids_movies = csv_to_dict(f'data/ids_movies_{start_year}-{end_year}.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "938d5985",
   "metadata": {},
   "source": [
    "Now we can define the functions to make asynchronous calls to the API using the GET movie details endpoint:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f81f4d4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_tasks_details(session, url_details, details_params, ids_movies):\n",
    "    tasks = []\n",
    "    for id_movie, processing_state in ids_movies.items():\n",
    "        if processing_state==0:\n",
    "            tasks.append(session.get(url_details + str(id_movie), params=details_params, timeout = 15))\n",
    "    return tasks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7ae4580",
   "metadata": {},
   "outputs": [],
   "source": [
    "async def details_api_call(url, details_params, ids_movies, output_file, max_tries=3):\n",
    "    exceptions = []\n",
    "    movie_counter = 0\n",
    "    try_counter = 0\n",
    "    max_step = 1000\n",
    "    step = max_step\n",
    "    existing_ids = set()\n",
    "    if os.path.exists(output_file):\n",
    "        with open(output_file, \"r\") as f:\n",
    "            for line in f:\n",
    "                movie = json.loads(line)\n",
    "                existing_ids.add(str(movie['id']))\n",
    "    with open(output_file, \"a\") as f:\n",
    "        while try_counter < max_tries:\n",
    "            async with aiohttp.ClientSession() as session:\n",
    "                tasks = get_tasks_details(session, url, details_params, ids_movies)\n",
    "                if not tasks:\n",
    "                    return exceptions\n",
    "                if len(tasks) < max_step:\n",
    "                    step = len(tasks)\n",
    "                for i in range(0, len(tasks), step):\n",
    "                    batch = tasks[i:i+step]\n",
    "                    responses = await asyncio.gather(*batch, return_exceptions=True)\n",
    "                    for response in responses:\n",
    "                        try:\n",
    "                            movie = await response.json()\n",
    "                            if movie['id'] and str(movie['id']) not in existing_ids:\n",
    "                                json.dump(movie, f)\n",
    "                                f.write('\\n')\n",
    "                                existing_ids.add(str(movie['id']))\n",
    "                                ids_movies[str(movie['id'])] = 1\n",
    "                                movie_counter += 1\n",
    "                                clear_output(wait=True)\n",
    "                                print(f'{movie_counter} movies out of {len(ids_movies)} have been fetched')\n",
    "                        except:\n",
    "                            exceptions.append(response)\n",
    "            try_counter += 1\n",
    "    return exceptions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed263c3c",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "start = time.monotonic()\n",
    "detailed_movies = await details_api_call(url_details, details_params, ids_movies, output_file = 'data/processed_movies_ids.jsonl')\n",
    "end = time.monotonic()\n",
    "\n",
    "print(f'Elapsed time: {round(end - start, 2)} seconds')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "480ea6d2",
   "metadata": {},
   "source": [
    "### Streaming companies"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab2d4977",
   "metadata": {},
   "source": [
    "For the streaming companies, data must be fetched using a particular endpoint different from GET movie details. We read again the movie IDs from the external csv file:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73d2deca",
   "metadata": {},
   "outputs": [],
   "source": [
    "ids_movies = csv_to_dict(f'data/ids_movies_{start_year}-{end_year}.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78a7faf3",
   "metadata": {},
   "source": [
    "We define some query parameters:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f05e4ca7",
   "metadata": {},
   "outputs": [],
   "source": [
    "str_comps_url = \"https://api.themoviedb.org/3/movie/\"\n",
    "\n",
    "str_comps_endpoint = \"/watch/providers\"\n",
    "\n",
    "str_comp_params = {\n",
    "                \"api_key\": api_key,\n",
    "                \"watch-region\": \"ES\"\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a1f07bf",
   "metadata": {},
   "source": [
    "And the asynchronous functions to make the requests:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "828b06fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_tasks_str_comps(session, url_str_comp, str_comps_endpoint, str_comp_params, ids_movies):\n",
    "    tasks = []\n",
    "    for id_movie, processing_state in ids_movies.items():\n",
    "        if processing_state==0:\n",
    "            tasks.append(session.get(str_comps_url + str(id_movie) + str_comps_endpoint, params=str_comp_params, timeout = 15))\n",
    "    return tasks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7329940",
   "metadata": {},
   "outputs": [],
   "source": [
    "async def str_comp_api_call(str_comps_url, str_comps_endpoint, str_comp_params, ids_movies, output_file, max_tries=3):\n",
    "    exceptions = []\n",
    "    movie_counter = 0\n",
    "    try_counter = 0\n",
    "    max_step = 1000\n",
    "    step = max_step\n",
    "    existing_ids = set()\n",
    "    if os.path.exists(output_file):\n",
    "        with open(output_file, \"r\") as f:\n",
    "            for line in f:\n",
    "                movie = json.loads(line)\n",
    "                existing_ids.add(str(movie['id']))\n",
    "                movie_counter += 1\n",
    "                ids_movies[str(movie['id'])] = 1\n",
    "    with open(output_file, \"a\") as f:\n",
    "        while try_counter < max_tries:\n",
    "            async with aiohttp.ClientSession() as session:\n",
    "                tasks = get_tasks_str_comps(session, str_comps_url, str_comps_endpoint,str_comp_params, ids_movies)\n",
    "                if not tasks:\n",
    "                    return exceptions, movie_counter\n",
    "                if len(tasks) < max_step:\n",
    "                    step = len(tasks)\n",
    "                for i in range(0, len(tasks), step):\n",
    "                    batch = tasks[i:i+step]\n",
    "                    responses = await asyncio.gather(*batch, return_exceptions=True)\n",
    "                    for response in responses:\n",
    "                        try:\n",
    "                            str_comps = await response.json()\n",
    "                            if str(str_comps['id']) not in existing_ids:\n",
    "                                json.dump(str_comps, f)\n",
    "                                f.write('\\n')\n",
    "                                existing_ids.add(str(str_comps['id']))\n",
    "                                ids_movies[str(str_comps['id'])] = 1\n",
    "                                movie_counter += 1\n",
    "                                clear_output(wait=True)\n",
    "                                print(f'Watch providers for {movie_counter} movies out of {len(ids_movies)} have been fetched')\n",
    "                        except:\n",
    "                            exceptions.append(response)\n",
    "            try_counter += 1\n",
    "    return exceptions, movie_counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e2cb539",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "start = time.monotonic()\n",
    "exceptions, movie_counter = await str_comp_api_call(str_comps_url, str_comps_endpoint, str_comp_params, ids_movies, output_file = 'data/str_comps.jsonl', max_tries=3)\n",
    "end = time.monotonic()\n",
    "\n",
    "print(f'Elapsed time: {round(end - start, 2)} seconds')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12d4f3d4",
   "metadata": {},
   "source": [
    "### Table population"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "519e19e4",
   "metadata": {},
   "source": [
    "With the obtained list of movies we can now feed multiple functions to populate the SQL database:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "baa00f77",
   "metadata": {},
   "outputs": [],
   "source": [
    "def populate_movie(movies):\n",
    "    insert_query = \"\"\"\n",
    "    INSERT INTO movie\n",
    "    (id_movie, original_title, original_language, overview, popularity, poster_path, release_date, title, vote_average, vote_count, budget, revenue, runtime)\n",
    "    VALUES(%s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s)\n",
    "    \"\"\"\n",
    "    \n",
    "    records = [(m['id'], m['original_title'], m['original_language'], m['overview'], m['popularity'], m['poster_path'], m['release_date'], m['title'], m['vote_average'], m['vote_count'], m['budget'], m['revenue'], m['runtime']) for m in movies]\n",
    "    \n",
    "    cursor.executemany(insert_query, records)\n",
    "    \n",
    "    db.commit()\n",
    "    \n",
    "    return cursor.rowcount"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce3159c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def populate_prod_comp(movies):\n",
    "    insert_query = \"\"\"\n",
    "    INSERT IGNORE INTO prod_comp\n",
    "    (id_prod_comp, name, origin_country)\n",
    "    VALUES(%s, %s, %s)\n",
    "    \"\"\"\n",
    "    \n",
    "    prod_comps = [(prod_comp['id'], \n",
    "                   prod_comp['name'], \n",
    "                   prod_comp['origin_country']) \n",
    "                  for movie in movies\n",
    "                  for prod_comp in movie['production_companies']]\n",
    "                              \n",
    "    cursor.executemany(insert_query, prod_comps)\n",
    "    db.commit()\n",
    "    \n",
    "    return cursor.rowcount"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65bdbe9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def populate_movie_prod_comp(movies):\n",
    "    insert_query = \"\"\"\n",
    "    INSERT INTO movie_prod_comp\n",
    "    (id_movie, id_prod_comp)\n",
    "    VALUES(%s, %s)\n",
    "    \"\"\"\n",
    "    \n",
    "    movie_prod_comp = [(m['id'],\n",
    "                        prod_comp['id']) \n",
    "                       for m in movies \n",
    "                       for prod_comp in m['production_companies']]\n",
    "    \n",
    "    cursor.executemany(insert_query, movie_prod_comp)\n",
    "    \n",
    "    db.commit()\n",
    "    \n",
    "    return cursor.rowcount"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab3756ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "def populate_movie_genre(movies):\n",
    "    insert_query = \"\"\"\n",
    "    INSERT INTO movie_genre\n",
    "    (id_movie, id_genre)\n",
    "    VALUES(%s, %s)\n",
    "    \"\"\"\n",
    "    movie_genre = [(m['id'], \n",
    "                     genre['id']) \n",
    "                    for m in movies \n",
    "                    for genre in m['genres']]\n",
    "    \n",
    "    cursor.executemany(insert_query, movie_genre)\n",
    "    \n",
    "    db.commit()\n",
    "    \n",
    "    return cursor.rowcount"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a6d94e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def populate_person(movies, jobs):\n",
    "    insert_query = \"\"\"\n",
    "    INSERT IGNORE INTO person\n",
    "    (id_person, name, gender)\n",
    "    VALUES(%s, %s, %s)\n",
    "    \"\"\"\n",
    "    \n",
    "    actors = [(actor['id'], \n",
    "               actor['name'], \n",
    "               actor['gender']) \n",
    "              for m in movies \n",
    "              for actor in m['credits']['cast'][0:7]]\n",
    "    \n",
    "    crew = [(crew_mem['id'], \n",
    "             crew_mem['name'], \n",
    "             crew_mem['gender']) \n",
    "            for m in movies \n",
    "            for crew_mem in m['credits']['crew']\n",
    "            if crew_mem['job'] in jobs]\n",
    "    \n",
    "    cursor.executemany(insert_query, actors + crew)\n",
    "    \n",
    "    db.commit()\n",
    "    \n",
    "    return cursor.rowcount"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae20b46c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def populate_movie_person(movies, jobs):\n",
    "    insert_query = \"\"\"\n",
    "    INSERT INTO movie_person\n",
    "    (id_movie, id_person, id_job)\n",
    "    VALUES(%s, %s, %s)\n",
    "    \"\"\"\n",
    "    \n",
    "    movies_actors = [(m['id'], \n",
    "                      actor['id'], \n",
    "                      jobs.index('Actor') + 1)\n",
    "                     for m in movies \n",
    "                     for actor in m['credits']['cast'][0:7]]\n",
    "    \n",
    "    movies_crew = [(m['id'], \n",
    "                    crew_mem['id'], \n",
    "                    jobs.index(crew_mem['job']) + 1) \n",
    "                   for m in movies \n",
    "                   for crew_mem in m['credits']['crew']\n",
    "                   if crew_mem['job'] in jobs]\n",
    "    \n",
    "    cursor.executemany(insert_query, movies_actors + movies_crew)\n",
    "    \n",
    "    db.commit()\n",
    "    \n",
    "    return cursor.rowcount"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62ad3818",
   "metadata": {},
   "outputs": [],
   "source": [
    "def populate_movie_str_comp(str_comps):\n",
    "    \n",
    "    insert_query = \"\"\"\n",
    "    INSERT INTO movie_str_comp\n",
    "    (id_movie, id_str_comp)\n",
    "    VALUES(%s, %s)\n",
    "    \"\"\"\n",
    "    flatrate_es_comps = []\n",
    "    \n",
    "    for str_comp in str_comps:\n",
    "        id_movie = str_comp.get(\"id\")\n",
    "        flatrates = str_comp.get(\"results\", {}).get(\"ES\", {}).get(\"flatrate\", [])\n",
    "        for flatrate in flatrates:\n",
    "            provider_id = flatrate.get(\"provider_id\")\n",
    "            flatrate_es_comps.append((id_movie, provider_id))\n",
    "    \n",
    "    cursor.executemany(insert_query, flatrate_es_comps)\n",
    "    \n",
    "    db.commit()\n",
    "    \n",
    "    return cursor.rowcount"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09207386",
   "metadata": {},
   "source": [
    "Finally, we populate every table on the SQL database by dividing the movies list into chunks:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00287543",
   "metadata": {},
   "outputs": [],
   "source": [
    "jobs = ['Actor', 'Director','Screenplay']\n",
    "\n",
    "# Define the chunk size\n",
    "chunk_size = 1000\n",
    "\n",
    "# Read the JSONL file in chunks\n",
    "for chunk in pd.read_json('data/processed_movies_ids.jsonl', lines=True, chunksize=chunk_size):\n",
    "    # Convert the chunk to a list of dictionaries\n",
    "    movies = chunk.to_dict(orient='records')\n",
    "    \n",
    "    populate_movie(movies)\n",
    "    populate_prod_comp(movies)\n",
    "    populate_movie_prod_comp(movies)\n",
    "    populate_movie_genre(movies)\n",
    "    populate_person(movies, jobs)\n",
    "    populate_movie_person(movies, jobs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ecbc5035",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Define the chunk size\n",
    "chunk_size = 1000\n",
    "\n",
    "for chunk in pd.read_json('data/str_comps.jsonl', lines=True, chunksize=chunk_size):\n",
    "    # Convert the chunk to a list of dictionaries\n",
    "    str_comps = chunk.to_dict(orient='records')\n",
    "    \n",
    "    populate_movie_str_comp(str_comps)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45a87497",
   "metadata": {},
   "source": [
    "## EDA (Exploratory Data Analysis)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b74a4ba",
   "metadata": {},
   "source": [
    "## Recommendation model"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": true,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "357.487px"
   },
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
