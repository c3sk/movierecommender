{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "bba74bd7",
   "metadata": {},
   "source": [
    "# TFM Final Project <img style=\"display: inline; align-right: 250px; position: absolute; right: 0px;\" src=\"files/Logo-AIT-Red600x-8.webp\" width=\"130\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d0501b5",
   "metadata": {},
   "source": [
    "ðŸ‘‰ Berta Pfaff</br>\n",
    "ðŸ‘‰ Sergio Salvador</br>\n",
    "ðŸ‘‰ Francesc VilarÃ³</br>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1686877",
   "metadata": {},
   "source": [
    "# Project motivation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5294dfc",
   "metadata": {},
   "source": [
    "**Movie recommendation systems have become increasingly popular in recent years** due to the vast amount of movies available for viewers to watch. With the rise of streaming services like Netflix, Hulu, and Amazon Prime, **it has become harder for viewers to decide which movie to watch**, given the plethora of options available.\n",
    "\n",
    "The proposed project aims to **build a movie recommender system using Python, leveraging the TMDB API to fetch movie metadata from 1980 until 2023**. The TMDB (The Movie Database) is an online database that provides comprehensive information related to movies, TV shows, and other forms of visual media. It is a community-driven platform that is curated and maintained by a team of editors and contributors who gather information from various sources, such as film studios, production companies, and fan communities, among others. The TMDB API (Application Programming Interface) provides developers with access to this wealth of data, allowing them to retrieve and use movie and TV show metadata in their own applications and projects.\n",
    "\n",
    "The project will consist of three main parts:\n",
    "\n",
    "1. **Database design**: An Entity-Relationship model (ERM) will be first created, defining the entities, attributes, and relationships that need to be stored in the database. The next step is to create tables that correspond to the entities and attributes identified in the previous step. Each table should contain columns for the various attributes, along with appropriate data types and constraints.\n",
    "\n",
    "\n",
    "2. **Data fetching**: Asynchronous calls to the TMDB API will be used to fetch movie data, such as title, genre, release date, and ratings, among others. Traditional methods such as synchronous API requests would be to slow and inefficient for this aplication. Finally, data will be stored in a mySQL database, allowing for high performance and fast access.\n",
    "\n",
    "\n",
    "3. **EDA (Exploratory Data Analysis)**: Data visualization techniques will be applied to explore and understand the data. Graphs, charts, and histograms will be used to identify trends, patterns, and outliers, which can help improve the model's accuracy and obtain an overall understanding of the movie market in the last 40 years.\n",
    "\n",
    "\n",
    "4. **Recommendation model**: A model will be built using advanced machine learning algorithms. The model will be trained on the movie metadata to generate personalized movie recommendations. the proposed model will utilize a complex algorithm that takes into consideration numerous variables, such as the movie's plot overview, the cast of actors, and the directors involved in its production, among other factors, to ultimately <u>recommend a set of five other movies that share similarities and patterns with the original movie</u>. This comprehensive approach not only provides a reliable and accurate way to suggest new movie options to viewers but also ensures that the recommended movies align with the viewer's preferences and tastes, resulting in a highly personalized and satisfying viewing experience.\n",
    "\n",
    "Overall, this project aims to provide a convenient and personalized movie recommendation system that can help users discover new movies they will enjoy. Additionally, the project will also provide an opportunity to learn and apply several data science techniques learned throughout the master's degree, such as data retrieval, data visualization, and machine learning."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a0ceada",
   "metadata": {},
   "source": [
    "# Imported libraries"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41979533",
   "metadata": {},
   "source": [
    "The following libraries have been used to accomplish the following project:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "00323ac4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import mysql.connector\n",
    "import pandas as pd\n",
    "import warnings\n",
    "import requests\n",
    "import time\n",
    "from IPython.display import clear_output\n",
    "import csv\n",
    "from datetime import date, timedelta\n",
    "import ast\n",
    "import asyncio\n",
    "import aiohttp\n",
    "import os\n",
    "import json"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "061cddb2",
   "metadata": {},
   "source": [
    "## Database design"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d5451bb",
   "metadata": {},
   "source": [
    "### Database creation and connection"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b73463b9",
   "metadata": {},
   "source": [
    "Connection to a local mySQL server is established using the 'mysql.connector' library and providing the needed parameters. Finally, a cursor object is instantiated to allow interaction with the database."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "48ebb7e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "warnings.filterwarnings(\"ignore\") # Warnings are disabled\n",
    "\n",
    "db = mysql.connector.connect(\n",
    "    host = \"localhost\",\n",
    "    user = \"root\",\n",
    "    password= \"12345\"\n",
    ")\n",
    "\n",
    "cursor = db.cursor()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8cab986f",
   "metadata": {},
   "source": [
    "A new database called 'TMDB' is created and connection to server is established again, this time specifying the 'TMDB' database in the 'database' parameter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0aa5c3ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "cursor.execute(\"CREATE DATABASE TMDB\")\n",
    "db.commit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5fdc6a9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "warnings.filterwarnings(\"ignore\") # Warnings are disabled\n",
    "\n",
    "db = mysql.connector.connect(\n",
    "    host = \"localhost\",\n",
    "    user = \"root\",\n",
    "    password= \"12345\",\n",
    "    database= \"TMDB\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93fa6399",
   "metadata": {},
   "source": [
    "### API schema analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e58f5a69",
   "metadata": {},
   "source": [
    "Before starting to design the structure of the database, an in-depth analysis of the structure and content of the responses that the TMDB API provides is needed, in order to identify the entities, attributes, and relationships that exist in the data model.\n",
    "\n",
    "The TMDB API provides some endpoints of interest to this project:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f9fa75f",
   "metadata": {},
   "source": [
    "#### GET discover/movies"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1cfbed52",
   "metadata": {},
   "source": [
    "The GET discover/movie endpoint in the TMDB API **retrieves a list of movies that match certain criteria**. This endpoint allows users to discover movies by exploring different filtering options, such as release year, genre, language, and more. When making a request to the GET discover/movie endpoint, you can include various query parameters to customize the search criteria. For example, you can specify a minimum or maximum release date, a specific language, or a specific genre ID.\n",
    "\n",
    "The response to a GET discover/movie request includes a list of movies that match the specified criteria, along with metadata such as the movie title, release date, poster image, and more. Each movie in the response is represented as an object with various fields that provide information about the movie.\n",
    "\n",
    "For this project in particular, we need to fetch all movies from 1980 to 2023, so we will be using the following query parameters:\n",
    " - **\"primary_release_date.gte\"**: Allows to obtain movies whose release date is greater than or equal to the input date\n",
    " - **\"primary_release_date.lte\"**: Allows to obtain movies whose release date is lower than or equal to the input date\n",
    " - **\"page\"**: Every request returns only 20 results at a time, so a page parameter is needed to fetch all the results\n",
    " \n",
    " An example of a request using the GET discover/movie endpoint with only one result would be:\n",
    "\n",
    "<img src=\"files/example_GET_discover_movie.png\" style=\"border: 1px solid black;\">\n",
    "\n",
    "We will need more information on each movie than the one provided by the GET discover/movie endpoint, so we will be using this method to fetch only the movie id's from every movie from 1980 to 2023."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "452a6234",
   "metadata": {},
   "source": [
    "#### GET movie details endpoint"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3af7d394",
   "metadata": {},
   "source": [
    "Once we get all the IDs from the movies we can use GET movie/details endpoint in the TMDB API to retrieve all the details of a specific movie identified by its unique movie ID. This endpoint allows you to retrieve comprehensive information about a movie, including its title, overview, release date, runtime, genres, production companies, cast and crew, ratings, posters, trailers, and more.\n",
    "\n",
    "To use this endpoint, you need to provide the movie ID as a path parameter in the URL of the API request. For example, to retrieve the details of the movie \"The Godfather\" (which has a movie ID of 238), you would make a GET request to the following URL:\n",
    "\n",
    "https://api.themoviedb.org/3/movie/238?api_key=YOUR_API_KEY\n",
    "\n",
    "In the response from this endpoint, you will receive a JSON object containing all the available information about the movie, structured according to the TMDB API data model. Following the same example, the requested JSON object for \"The Godfather\" movie would be:\n",
    "\n",
    "<img src=\"files/example_GET_movie_details.png\" style=\"border: 1px solid black;\">\n",
    "\n",
    "Has you can see, the previous request is more complete that the one provided by the GET discover/movie endpoint. Still, no information about the cast and the crew involved in the making of the movie is provided. To obtain this information we will have to use the append_to_response parameter. This parameter allows to include additional information about a movie in the API response, such has cast and crew."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12c245c4",
   "metadata": {},
   "source": [
    "#### GET genre/movie/list endpoint"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c55a34e6",
   "metadata": {},
   "source": [
    "The GET /genre/movie/list endpoint in the TMDB API is used to retrieve a list of all the movie genres available in the TMDB database.\n",
    "\n",
    "When you make a request to this endpoint, you will receive a JSON object containing an array of genre objects, each of which includes the following information:\n",
    "\n",
    "- id: A unique identifier for the genre.\n",
    "- name: The name of the genre.\n",
    "\n",
    "Here is an example response from the GET /genre/movie/list endpoint:\n",
    "\n",
    "<img src=\"files/example_GET_genre_movie_list.png\" style=\"border: 1px solid black;\">\n",
    "\n",
    "You can use the id values returned from this endpoint to filter movies by genre in other TMDB API endpoints, such as the GET discover/movie endpoint, which allows you to search for movies based on various criteria, including genre."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b1b8653",
   "metadata": {},
   "source": [
    "#### GET /watch/providers/movie endpoint"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad4ab1d2",
   "metadata": {},
   "source": [
    "The GET /watch/providers/movie endpoint in the TMDB API is used to retrieve information about all the streaming companies available in the TMDB platform.\n",
    "\n",
    "When you make a request to this endpoint, you can include the watch_region parameter to specify the ISO 3166-1 code for the region you're interested in.\n",
    "\n",
    "The response to this request will include an object containing the following information:\n",
    "\n",
    "\n",
    "- results: An array of provider objects, each of which includes the following information:\n",
    " - display_priority: The display priority of the provider for the movie in the specified region.\n",
    " - logo_path: The path to the logo image for the provider.\n",
    " - provider_name: The name of the streaming provider.\n",
    " - provider_id: The ID of the streaming provider.\n",
    "\n",
    "For example, to retrieve all the movie providers in Spain, we would make a GET request to the following URL\n",
    "\n",
    "https://api.themoviedb.org/3/watch/providers/movie?api_key=YOUR_API_KEY&watch_region=ES\n",
    "\n",
    "Which would return the following response:\n",
    "\n",
    "<img src=\"files/example_GET_watch_providers_movie.png\" style=\"border: 1px solid black;\">\n",
    "\n",
    "Please note that a portion of the response above has been ommited to avoid overwhelming the screen with excessive information."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b7e32fd",
   "metadata": {},
   "source": [
    "## GET movie providers"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8c04a36",
   "metadata": {},
   "source": [
    "Since the append_to_response parameter in the GET movie details endpoint doesn't support watch providers, we have to fetch them separately using GET watch providers.\n",
    "\n",
    "The GET watch providers method is a function of the TMDB API that allows you to retrieve a list of streaming providers for a specific movie. This method provides information about where you can watch a particular title, along with links to the corresponding streaming service.\n",
    "\n",
    "To use this method, you need to make a GET request to the following endpoint:\n",
    "\n",
    "https://api.themoviedb.org/3/movie/{movie_id}/watch/providers?api_key=YOUR_API_KEY\n",
    "\n",
    "To use this endpoint, you need to provide the movie ID as a path parameter in the URL of the API request. For example, to retrieve the watch providers for the movie \"The Godfather\" (which has a movie ID of 238), you would make a GET request to the following URL:\n",
    "\n",
    "https://api.themoviedb.org/3/movie/238/watch/providers?api_key=YOUR_API_KEY\n",
    "\n",
    "In the response from this endpoint, you will receive a JSON object containing all the available information about the available watch providers. Following the same example, the requested JSON object for \"The Godfather\" movie would be:\n",
    "\n",
    "\n",
    "<img src=\"files/example_GET_watch_providers.png\" style=\"border: 1px solid black; width:800px\">\n",
    "\n",
    "Please note that a portion of the response above has been ommited to avoid overwhelming the screen with excessive information."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fbe725c3",
   "metadata": {},
   "source": [
    "### Entity-Relationship model (ERM)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e523471",
   "metadata": {},
   "source": [
    "An ERM model is firstly defined to represent the entities and relationships of the database. \n",
    "\n",
    "The database will consist of the following main tables:\n",
    "\n",
    "- **movie_ table**: The main table. This table will store the data unique to every movie, such as title, overview or runtime.\n",
    "- **str_comp_ table**: Stores all the flatrate streaming companies available in Spain\n",
    "- **prod_comp table**: Stores all the production companies\n",
    "- **genre table**: Stores all the available genres in the TMDB platform\n",
    "- **person table**: Stores the main crew and cast that have been involved in the movies of the database.\n",
    "- **jobs table**: Stores the jobs that will be considered for adding a person to the database. In this case, only roles of actor, director and screenplay have been considered.\n",
    "\n",
    "Junction tables (red tables on the ERM diagram) are needed to avoid many-to-many relationships between the main table and every other table. For instance, for a particular movie, there can be various streaming companies and a particular streaming company can stream various movies. This kind of relationship is impossible to represent in a structured database such as SQL, so a middle table is created to relate both tables using foreign keys.\n",
    "\n",
    "The meaning of each attribute for each table will be explained as we create them, so as not to clutter this Jupyter cell with too much text."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef2c6c18",
   "metadata": {},
   "source": [
    "<img src=\"files/DB_ERM_v2.png\" style=\"width:700px\">"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a172817",
   "metadata": {},
   "source": [
    "### Table creation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "690c6444",
   "metadata": {},
   "source": [
    "#### movie table creation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "710b1a2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "query_movie = \"\"\"\n",
    "    CREATE TABLE movie(\n",
    "        id_movie int,\n",
    "        original_title varchar(300),\n",
    "        original_language varchar(20), \n",
    "        overview varchar(1000),\n",
    "        popularity float,\n",
    "        poster_path varchar(200),\n",
    "        release_date varchar(20),\n",
    "        title varchar(300),\n",
    "        vote_average float,\n",
    "        vote_count int,\n",
    "        budget int, \n",
    "        revenue bigint,\n",
    "        runtime int,\n",
    "        PRIMARY KEY (id_movie)\n",
    "    )\n",
    "\"\"\"\n",
    "\n",
    "cursor.execute(query_movie)\n",
    "db.commit()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e72c3db",
   "metadata": {},
   "source": [
    "#### Streaming companies"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7873f80b",
   "metadata": {},
   "source": [
    "##### str_comp table creation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e1f5777a",
   "metadata": {},
   "outputs": [],
   "source": [
    "query_str_comp = \"\"\"\n",
    "    CREATE TABLE str_comp (\n",
    "    id_str_comp int AUTO_INCREMENT,\n",
    "    name varchar(50),\n",
    "    PRIMARY KEY (id_str_comp)\n",
    ")\n",
    "\"\"\"\n",
    "\n",
    "cursor.execute(query_str_comp)\n",
    "db.commit()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf884840",
   "metadata": {},
   "source": [
    "##### movie_str_comp junction table creation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "518c9ac4",
   "metadata": {},
   "outputs": [],
   "source": [
    "query_movie_str_comp = \"\"\"\n",
    "    CREATE TABLE movie_str_comp (\n",
    "    id_mov_str_comp int AUTO_INCREMENT,\n",
    "    id_movie int,\n",
    "    id_str_comp int,\n",
    "    PRIMARY KEY (id_mov_str_comp),\n",
    "    FOREIGN KEY (id_movie) REFERENCES movie(id_movie),\n",
    "    FOREIGN KEY (id_str_comp) REFERENCES str_comp(id_str_comp)\n",
    ")\n",
    "\"\"\"\n",
    "\n",
    "cursor.execute(query_movie_str_comp)\n",
    "db.commit()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8e15bd3",
   "metadata": {},
   "source": [
    "#### Production companies"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1eb91f49",
   "metadata": {},
   "source": [
    "##### prod_comp table creation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ad43874b",
   "metadata": {},
   "outputs": [],
   "source": [
    "query_prod_comp = \"\"\"\n",
    "    CREATE TABLE prod_comp ( \n",
    "         id_prod_comp int NOT NULL,\n",
    "         name varchar (100),\n",
    "         origin_country varchar (20),\n",
    "\n",
    "         PRIMARY KEY (id_prod_comp)\n",
    "      )\n",
    "\"\"\"\n",
    "cursor.execute(query_prod_comp)\n",
    "db.commit()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39ce4afc",
   "metadata": {},
   "source": [
    "##### movie_prod_comp junction table creation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d787677d",
   "metadata": {},
   "outputs": [],
   "source": [
    "query_movie_prod_comp = \"\"\"\n",
    "    CREATE TABLE movie_prod_comp (\n",
    "        id_mov_prod_comp int AUTO_INCREMENT,\n",
    "        id_movie int,\n",
    "        id_prod_comp int,\n",
    "        \n",
    "        PRIMARY KEY (id_mov_prod_comp),\n",
    "        FOREIGN KEY (id_movie) REFERENCES movie(id_movie),\n",
    "        FOREIGN KEY (id_prod_comp) REFERENCES prod_comp(id_prod_comp)\n",
    "      )\n",
    "\"\"\"\n",
    "cursor.execute(query_movie_prod_comp)\n",
    "db.commit()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "763cb12d",
   "metadata": {},
   "source": [
    "#### Genres"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63debe16",
   "metadata": {},
   "source": [
    "##### genre table creation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "76b74deb",
   "metadata": {},
   "outputs": [],
   "source": [
    "query_genre = \"\"\"\n",
    "    CREATE TABLE genre ( \n",
    "         id_genre int NOT NULL,\n",
    "         genre varchar (30),\n",
    "\n",
    "         PRIMARY KEY(id_genre)\n",
    "      )\n",
    "\"\"\"\n",
    "cursor.execute(query_genre)\n",
    "db.commit()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ed41106",
   "metadata": {},
   "source": [
    "##### movie_genre table creation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "785e1eec",
   "metadata": {},
   "outputs": [],
   "source": [
    "query_movie_genre = \"\"\"\n",
    "    CREATE TABLE movie_genre (\n",
    "        id_mov_genre int AUTO_INCREMENT,\n",
    "        id_movie int,\n",
    "        id_genre int,\n",
    "\n",
    "        PRIMARY KEY (id_mov_genre),\n",
    "        FOREIGN KEY (id_movie) REFERENCES movie(id_movie),\n",
    "        FOREIGN KEY (id_genre) REFERENCES genre(id_genre)\n",
    "      )\n",
    "\"\"\"\n",
    "cursor.execute(query_movie_genre)\n",
    "db.commit()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bee441bb",
   "metadata": {},
   "source": [
    "#### People"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7bc5787",
   "metadata": {},
   "source": [
    "##### _person_ table creation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "874a0313",
   "metadata": {},
   "outputs": [],
   "source": [
    "query_person = \"\"\"\n",
    "    CREATE TABLE person ( \n",
    "         id_person int NOT NULL,\n",
    "         name varchar (50),\n",
    "         gender int,\n",
    "\n",
    "         PRIMARY KEY (id_person)\n",
    "      )\n",
    "\"\"\"\n",
    "cursor.execute(query_person)\n",
    "db.commit()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27a52eac",
   "metadata": {},
   "source": [
    "##### job table creation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "1445d87a",
   "metadata": {},
   "outputs": [],
   "source": [
    "query_job = \"\"\"\n",
    "    CREATE TABLE job (\n",
    "        id_job int AUTO_INCREMENT,\n",
    "        job_name varchar(50),\n",
    "        \n",
    "        PRIMARY KEY (id_job)\n",
    "      )\n",
    "\"\"\"\n",
    "cursor.execute(query_job)\n",
    "db.commit()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ff1dbc1",
   "metadata": {},
   "source": [
    "##### movie_person junction table creation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "67a42cbd",
   "metadata": {},
   "outputs": [],
   "source": [
    "query_movie_person = \"\"\"\n",
    "    CREATE TABLE movie_person ( \n",
    "         id_mov_person int AUTO_INCREMENT,\n",
    "         id_movie int,\n",
    "         id_person int,\n",
    "         id_job int,\n",
    "\n",
    "         PRIMARY KEY (id_mov_person),\n",
    "         FOREIGN KEY (id_movie) REFERENCES movie(id_movie),\n",
    "         FOREIGN KEY (id_person) REFERENCES person(id_person),\n",
    "         FOREIGN KEY (id_job) REFERENCES job(id_job)\n",
    "      )\n",
    "\"\"\"\n",
    "cursor.execute(query_movie_person)\n",
    "db.commit()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74ec106d",
   "metadata": {},
   "source": [
    "## Data fetching"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "42025516",
   "metadata": {},
   "outputs": [],
   "source": [
    "api_key = \"ac6862efab2ddf803567630c9f474ab8\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b96a2a6b",
   "metadata": {},
   "source": [
    "### Independent tables generation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6551e631",
   "metadata": {},
   "source": [
    "#### Genres table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "fd67c66c",
   "metadata": {},
   "outputs": [],
   "source": [
    "url_genres = \"https://api.themoviedb.org/3/genre/movie/list\"\n",
    "\n",
    "query_params = {\n",
    "                \"api_key\": api_key,\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "4406a8a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_genres(url_genres, query_params):\n",
    "    \"\"\"\n",
    "    This function sends a request to the TMDB API and returns a list of tuples \n",
    "    containing the id and name of all the available genres.\n",
    "    \"\"\"\n",
    "    response = requests.get(url_genres, query_params).json()\n",
    "    \n",
    "    genres = [(genre['id'], genre['name']) for genre in response['genres']]\n",
    "    \n",
    "    return genres"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "e6094ef4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(28, 'Action')"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "genres = get_genres(url_genres, query_params)\n",
    "genres[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "54041e7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def populate_genre(genres):\n",
    "    insert_query = \"\"\"\n",
    "    INSERT INTO genre\n",
    "    (id_genre, genre)\n",
    "    VALUES(%s, %s)\n",
    "    \"\"\"\n",
    "    \n",
    "    cursor.executemany(insert_query, genres)\n",
    "    db.commit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "0bb4c64b",
   "metadata": {},
   "outputs": [],
   "source": [
    "populate_genre(genres)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a3fb00f",
   "metadata": {},
   "source": [
    "#### Streaming Companies table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "60f1aaae",
   "metadata": {},
   "outputs": [],
   "source": [
    "url_str_comps = \"https://api.themoviedb.org/3/watch/providers/movie\"\n",
    "\n",
    "query_params_str_comps = {\n",
    "                \"api_key\": api_key,\n",
    "                \"watch-region\": \"ES\"\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "dee6a5b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_str_comps(url_str_comps, query_params_str_comp):\n",
    "    \"\"\"\n",
    "    This function sends a request to the TMDB API and returns a list of tuples \n",
    "    containing the id and name of all the available streaming companies. \n",
    "    \"\"\"\n",
    "    response = requests.get(url_str_comps, query_params_str_comps).json()\n",
    "    str_comps = [(result['provider_id'], result['provider_name']) for result in response['results']]\n",
    "    \n",
    "    return str_comps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "361f542e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2, 'Apple TV')"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "str_comps = get_str_comps(url_str_comps, query_params_str_comps)\n",
    "str_comps[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "794ebea4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def populate_str_comps(str_comps):\n",
    "    insert_query = \"\"\"\n",
    "    INSERT INTO str_comp\n",
    "    (id_str_comp, name)\n",
    "    VALUES(%s, %s)\n",
    "    \"\"\"\n",
    "    \n",
    "    cursor.executemany(insert_query, str_comps)\n",
    "    db.commit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "a9d60989",
   "metadata": {},
   "outputs": [],
   "source": [
    "populate_str_comps(str_comps)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e065abc7",
   "metadata": {},
   "source": [
    "#### Jobs table "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "93181799",
   "metadata": {},
   "outputs": [],
   "source": [
    "jobs = ['Actor', 'Director','Screenplay']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "209cd6ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "def populate_job(jobs):\n",
    "    insert_query = \"\"\"\n",
    "    INSERT INTO job\n",
    "    (job_name)\n",
    "    VALUES(%s)\n",
    "    \"\"\"\n",
    "    for job in jobs:\n",
    "        cursor.execute(insert_query, [job])\n",
    "    db.commit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "c3c0eaed",
   "metadata": {},
   "outputs": [],
   "source": [
    "populate_job(jobs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e1cecc1",
   "metadata": {},
   "source": [
    "### Movies IDs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "32840434",
   "metadata": {},
   "outputs": [],
   "source": [
    "# parameters\n",
    "\n",
    "start_year = 1980\n",
    "end_year = 1980\n",
    "\n",
    "url_discover = \"https://api.themoviedb.org/3/discover/movie\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "7ee91fb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def month_range_dict(start_year, end_year):\n",
    "    \"\"\"\n",
    "    Returns a dictionary that maps the first day of a month to the last day of the month, given a start and end year.\n",
    "    \"\"\"\n",
    "    month_range = {}\n",
    "    start_date = date(start_year, 1, 1)\n",
    "    end_date = date(end_year, 12, 31)\n",
    "\n",
    "    # Iterate over all months between start and end dates\n",
    "    while start_date < end_date:\n",
    "        year = start_date.year\n",
    "        month = start_date.month\n",
    "        last_day = (date(year, month, 1) + timedelta(days=32)).replace(day=1) - timedelta(days=1)\n",
    "        month_range[start_date.strftime('%Y-%m-%d')] = last_day.strftime('%Y-%m-%d')\n",
    "        start_date = last_day + timedelta(days=1)\n",
    "\n",
    "    return month_range"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "bfb9f220",
   "metadata": {},
   "outputs": [],
   "source": [
    "def total_pages(start_date, end_date, api_key, url_discover):\n",
    "    param = {'api_key': api_key,\n",
    "             'primary_release_date.gte': start_date,\n",
    "             'primary_release_date.lte': end_date,\n",
    "             'page': 500}\n",
    "    \n",
    "    return requests.get(url_discover, param).json()['total_pages']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "2d1e5e50",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "26762"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "total_pages('1980-01-01', '2023-12-31', api_key, url_discover)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "0bdf29ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "def params_generator(start_year, end_year, api_key, url_discover):\n",
    "    params = []\n",
    "    total_pag = 0\n",
    "    \n",
    "    for start_date, end_date in month_range_dict(start_year, end_year).items():\n",
    "        \n",
    "        total_pag = total_pages(start_date, end_date, api_key, url_discover)\n",
    "        \n",
    "        page = 1\n",
    "        \n",
    "        while page <= total_pag:\n",
    "            params.append({\n",
    "                \"api_key\": api_key,\n",
    "                \"primary_release_date.gte\": start_date,\n",
    "                \"primary_release_date.lte\": end_date,\n",
    "                \"page\": page\n",
    "            })\n",
    "            page += 1\n",
    "            \n",
    "    if not os.path.exists('data'):\n",
    "        os.makedirs('data')\n",
    "        \n",
    "    fieldnames = ['api_key', 'primary_release_date.gte', 'primary_release_date.lte', 'page']\n",
    "    \n",
    "    with open(f'data/discover_params_{start_year}_{end_year}.csv', 'w', newline='') as csvfile:\n",
    "        writer = csv.DictWriter(csvfile, fieldnames=fieldnames)\n",
    "        writer.writeheader()\n",
    "        for param in params:\n",
    "            writer.writerow(param)\n",
    "        \n",
    "    return params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "e43e1e30",
   "metadata": {},
   "outputs": [],
   "source": [
    "params = params_generator(start_year, end_year, api_key, url_discover)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "3d39272b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_discover_params_csv(csv_filepath):\n",
    "    json_list = []\n",
    "    with open(csv_filepath, 'r', newline='') as csvfile:\n",
    "        reader = csv.DictReader(csvfile)\n",
    "        for row in reader:\n",
    "            json_list.append(row)\n",
    "    return json_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "4a1effa4",
   "metadata": {},
   "outputs": [],
   "source": [
    "params = read_discover_params_csv(f'data/discover_params_{start_year}_{end_year}.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "90286b54",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'api_key': 'ac6862efab2ddf803567630c9f474ab8',\n",
       " 'primary_release_date.gte': '1980-01-01',\n",
       " 'primary_release_date.lte': '1980-01-31',\n",
       " 'page': '1'}"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "params[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "0555b6af",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_tasks_discover(session, url, params, processed_pages):\n",
    "    tasks = []\n",
    "    for i, param in enumerate(params):\n",
    "        if processed_pages[i]==0:\n",
    "            tasks.append((i, session.get(url, params=param, timeout = 15)))\n",
    "    return tasks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "c316a0f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "processed_pages = {}\n",
    "\n",
    "for i in range(len(params)):\n",
    "    processed_pages[i]=0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "5c54460f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0: 0,\n",
       " 1: 0,\n",
       " 2: 0,\n",
       " 3: 0,\n",
       " 4: 0,\n",
       " 5: 0,\n",
       " 6: 0,\n",
       " 7: 0,\n",
       " 8: 0,\n",
       " 9: 0,\n",
       " 10: 0,\n",
       " 11: 0,\n",
       " 12: 0,\n",
       " 13: 0,\n",
       " 14: 0,\n",
       " 15: 0,\n",
       " 16: 0,\n",
       " 17: 0,\n",
       " 18: 0,\n",
       " 19: 0,\n",
       " 20: 0,\n",
       " 21: 0,\n",
       " 22: 0,\n",
       " 23: 0,\n",
       " 24: 0,\n",
       " 25: 0,\n",
       " 26: 0,\n",
       " 27: 0,\n",
       " 28: 0,\n",
       " 29: 0,\n",
       " 30: 0,\n",
       " 31: 0,\n",
       " 32: 0,\n",
       " 33: 0,\n",
       " 34: 0,\n",
       " 35: 0,\n",
       " 36: 0,\n",
       " 37: 0,\n",
       " 38: 0,\n",
       " 39: 0,\n",
       " 40: 0,\n",
       " 41: 0,\n",
       " 42: 0,\n",
       " 43: 0,\n",
       " 44: 0,\n",
       " 45: 0,\n",
       " 46: 0,\n",
       " 47: 0,\n",
       " 48: 0,\n",
       " 49: 0,\n",
       " 50: 0,\n",
       " 51: 0,\n",
       " 52: 0,\n",
       " 53: 0,\n",
       " 54: 0,\n",
       " 55: 0,\n",
       " 56: 0,\n",
       " 57: 0,\n",
       " 58: 0,\n",
       " 59: 0,\n",
       " 60: 0,\n",
       " 61: 0,\n",
       " 62: 0,\n",
       " 63: 0,\n",
       " 64: 0,\n",
       " 65: 0,\n",
       " 66: 0,\n",
       " 67: 0,\n",
       " 68: 0,\n",
       " 69: 0,\n",
       " 70: 0,\n",
       " 71: 0,\n",
       " 72: 0,\n",
       " 73: 0,\n",
       " 74: 0,\n",
       " 75: 0,\n",
       " 76: 0,\n",
       " 77: 0,\n",
       " 78: 0,\n",
       " 79: 0,\n",
       " 80: 0,\n",
       " 81: 0,\n",
       " 82: 0,\n",
       " 83: 0,\n",
       " 84: 0,\n",
       " 85: 0,\n",
       " 86: 0,\n",
       " 87: 0,\n",
       " 88: 0,\n",
       " 89: 0,\n",
       " 90: 0,\n",
       " 91: 0,\n",
       " 92: 0,\n",
       " 93: 0,\n",
       " 94: 0,\n",
       " 95: 0,\n",
       " 96: 0,\n",
       " 97: 0,\n",
       " 98: 0,\n",
       " 99: 0,\n",
       " 100: 0,\n",
       " 101: 0,\n",
       " 102: 0,\n",
       " 103: 0,\n",
       " 104: 0,\n",
       " 105: 0,\n",
       " 106: 0,\n",
       " 107: 0,\n",
       " 108: 0,\n",
       " 109: 0,\n",
       " 110: 0,\n",
       " 111: 0,\n",
       " 112: 0,\n",
       " 113: 0,\n",
       " 114: 0,\n",
       " 115: 0,\n",
       " 116: 0,\n",
       " 117: 0,\n",
       " 118: 0,\n",
       " 119: 0,\n",
       " 120: 0,\n",
       " 121: 0,\n",
       " 122: 0,\n",
       " 123: 0,\n",
       " 124: 0,\n",
       " 125: 0,\n",
       " 126: 0,\n",
       " 127: 0,\n",
       " 128: 0,\n",
       " 129: 0,\n",
       " 130: 0,\n",
       " 131: 0,\n",
       " 132: 0,\n",
       " 133: 0,\n",
       " 134: 0,\n",
       " 135: 0,\n",
       " 136: 0,\n",
       " 137: 0,\n",
       " 138: 0,\n",
       " 139: 0,\n",
       " 140: 0,\n",
       " 141: 0,\n",
       " 142: 0,\n",
       " 143: 0,\n",
       " 144: 0,\n",
       " 145: 0,\n",
       " 146: 0,\n",
       " 147: 0,\n",
       " 148: 0,\n",
       " 149: 0,\n",
       " 150: 0,\n",
       " 151: 0,\n",
       " 152: 0,\n",
       " 153: 0,\n",
       " 154: 0,\n",
       " 155: 0,\n",
       " 156: 0,\n",
       " 157: 0,\n",
       " 158: 0,\n",
       " 159: 0,\n",
       " 160: 0,\n",
       " 161: 0,\n",
       " 162: 0,\n",
       " 163: 0,\n",
       " 164: 0,\n",
       " 165: 0,\n",
       " 166: 0,\n",
       " 167: 0,\n",
       " 168: 0,\n",
       " 169: 0,\n",
       " 170: 0,\n",
       " 171: 0,\n",
       " 172: 0,\n",
       " 173: 0,\n",
       " 174: 0,\n",
       " 175: 0,\n",
       " 176: 0,\n",
       " 177: 0,\n",
       " 178: 0,\n",
       " 179: 0,\n",
       " 180: 0,\n",
       " 181: 0,\n",
       " 182: 0,\n",
       " 183: 0,\n",
       " 184: 0,\n",
       " 185: 0,\n",
       " 186: 0,\n",
       " 187: 0,\n",
       " 188: 0,\n",
       " 189: 0,\n",
       " 190: 0,\n",
       " 191: 0,\n",
       " 192: 0,\n",
       " 193: 0,\n",
       " 194: 0,\n",
       " 195: 0,\n",
       " 196: 0,\n",
       " 197: 0,\n",
       " 198: 0,\n",
       " 199: 0,\n",
       " 200: 0,\n",
       " 201: 0,\n",
       " 202: 0,\n",
       " 203: 0,\n",
       " 204: 0,\n",
       " 205: 0,\n",
       " 206: 0,\n",
       " 207: 0,\n",
       " 208: 0,\n",
       " 209: 0,\n",
       " 210: 0,\n",
       " 211: 0,\n",
       " 212: 0,\n",
       " 213: 0,\n",
       " 214: 0,\n",
       " 215: 0,\n",
       " 216: 0,\n",
       " 217: 0,\n",
       " 218: 0,\n",
       " 219: 0,\n",
       " 220: 0,\n",
       " 221: 0,\n",
       " 222: 0,\n",
       " 223: 0,\n",
       " 224: 0,\n",
       " 225: 0,\n",
       " 226: 0,\n",
       " 227: 0,\n",
       " 228: 0,\n",
       " 229: 0,\n",
       " 230: 0,\n",
       " 231: 0}"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "processed_pages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "e81d3d4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "async def discover_api_call(url, params, processed_pages, max_tries=3):\n",
    "    results=[]\n",
    "    exceptions = []\n",
    "    page_counter = 0\n",
    "    try_counter = 0\n",
    "    max_step = 1000\n",
    "    step = max_step\n",
    "    while try_counter < max_tries:\n",
    "        async with aiohttp.ClientSession() as session:\n",
    "            tasks = get_tasks_discover(session, url, params, processed_pages)\n",
    "            if not tasks:\n",
    "                return results, exceptions\n",
    "            if len(tasks) < max_step:\n",
    "                step = len(tasks)\n",
    "            for i in range(0, len(tasks), step): #len(tasks)\n",
    "                batch = tasks[i:i+step]\n",
    "                responses = await asyncio.gather(*[t[1] for t in batch], return_exceptions=True)\n",
    "                #await asyncio.sleep()\n",
    "                for j, response in enumerate(responses):\n",
    "                    try:\n",
    "                        movies_page = await response.json()\n",
    "                        results.append(movies_page['results'])\n",
    "                        processed_pages[batch[j][0]] = 1\n",
    "                        page_counter += 1\n",
    "                        clear_output(wait=True)\n",
    "                        print(f'{page_counter} pages out of {len(params)} have been fetched')\n",
    "                    except:\n",
    "                        exceptions.append(response)\n",
    "        try_counter += 1\n",
    "    return results, exceptions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "2521e28b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "232 pages out of 232 have been fetched\n",
      "Elapsed time: 1.23 seconds\n"
     ]
    }
   ],
   "source": [
    "start = time.monotonic()\n",
    "discovered_movies, exceptions = await discover_api_call(url_discover, params, processed_pages)\n",
    "end = time.monotonic()\n",
    "\n",
    "print(f'Elapsed time: {round(end - start, 2)} seconds')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "d69d871b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_movie_ids(discovered_movies):\n",
    "    \n",
    "    if not os.path.exists('data'):\n",
    "        os.makedirs('data')\n",
    "    \n",
    "    movie_ids = {movie['id']: 0\n",
    "            for page in discovered_movies\n",
    "            for movie in page}\n",
    "    \n",
    "    with open(f'data/ids_movies_{start_year}-{end_year}.csv', 'w') as f:\n",
    "        for key in movie_ids.keys():\n",
    "            f.write(\"%s,%s\\n\"%(key,movie_ids[key]))\n",
    "            \n",
    "    print(f'{len(movie_ids)} movie IDs have been saved succesfully')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "089d9890",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4534 movie IDs have been saved succesfully\n"
     ]
    }
   ],
   "source": [
    "get_movie_ids(discovered_movies)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "393c2dfc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def csv_to_dict(filepath):\n",
    "    # create an empty dictionary to store the CSV data\n",
    "    csv_dict = {}\n",
    "\n",
    "    # open the CSV file in read mode\n",
    "    with open(filepath, 'r') as f:\n",
    "\n",
    "    # create a reader object to read the CSV data\n",
    "        reader = csv.reader(f)\n",
    "\n",
    "    # loop through each row in the CSV file\n",
    "        for row in reader:\n",
    "            csv_dict[row[0]] = ast.literal_eval(row[1])\n",
    "\n",
    "    return csv_dict"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "643db229",
   "metadata": {},
   "source": [
    "### Movie details"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "15e7a5a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "url_details = \"https://api.themoviedb.org/3/movie/\"\n",
    "\n",
    "details_params = {\n",
    "                \"api_key\": \"ac6862efab2ddf803567630c9f474ab8\",\n",
    "                \"append_to_response\": \"credits\"\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "662362ff",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'adult': False,\n",
       " 'backdrop_path': None,\n",
       " 'belongs_to_collection': None,\n",
       " 'budget': 0,\n",
       " 'genres': [{'id': 16, 'name': 'Animation'}, {'id': 12, 'name': 'Adventure'}],\n",
       " 'homepage': 'http://sethboyden.blogspot.com/',\n",
       " 'id': 337800,\n",
       " 'imdb_id': 'tt5062438',\n",
       " 'original_language': 'en',\n",
       " 'original_title': 'An Object at Rest',\n",
       " 'overview': \"From the director: An Object at Rest follows the life of a stone as it travels over the course of millennia, facing nature's greatest obstacle: human civilization. My final thesis film at CalArts!\",\n",
       " 'popularity': 0.6,\n",
       " 'poster_path': '/b4G0iUDbXK7E4aV2SpntMkSAv4F.jpg',\n",
       " 'production_companies': [],\n",
       " 'production_countries': [{'iso_3166_1': 'US',\n",
       "   'name': 'United States of America'}],\n",
       " 'release_date': '2015-05-01',\n",
       " 'revenue': 0,\n",
       " 'runtime': 5,\n",
       " 'spoken_languages': [{'english_name': 'English',\n",
       "   'iso_639_1': 'en',\n",
       "   'name': 'English'}],\n",
       " 'status': 'Released',\n",
       " 'tagline': '',\n",
       " 'title': 'An Object at Rest',\n",
       " 'video': False,\n",
       " 'vote_average': 6.4,\n",
       " 'vote_count': 7,\n",
       " 'credits': {'cast': [{'adult': False,\n",
       "    'gender': 0,\n",
       "    'id': 2152441,\n",
       "    'known_for_department': 'Acting',\n",
       "    'name': 'Miles Hartfelder',\n",
       "    'original_name': 'Miles Hartfelder',\n",
       "    'popularity': 0.6,\n",
       "    'profile_path': None,\n",
       "    'cast_id': 1,\n",
       "    'character': '',\n",
       "    'credit_id': '5bc64bb492514179c4079265',\n",
       "    'order': 0},\n",
       "   {'adult': False,\n",
       "    'gender': 3,\n",
       "    'id': 2152442,\n",
       "    'known_for_department': 'Acting',\n",
       "    'name': 'Zero Pilnik',\n",
       "    'original_name': 'Zero Pilnik',\n",
       "    'popularity': 0.6,\n",
       "    'profile_path': '/evA0BOCWrpr9sT0B6aJAfnWG1WU.jpg',\n",
       "    'cast_id': 2,\n",
       "    'character': '',\n",
       "    'credit_id': '5bc64bbe0e0a2613b0022a3a',\n",
       "    'order': 1},\n",
       "   {'adult': False,\n",
       "    'gender': 0,\n",
       "    'id': 2152443,\n",
       "    'known_for_department': 'Acting',\n",
       "    'name': 'Sarah Parsons',\n",
       "    'original_name': 'Sarah Parsons',\n",
       "    'popularity': 0.6,\n",
       "    'profile_path': None,\n",
       "    'cast_id': 3,\n",
       "    'character': '',\n",
       "    'credit_id': '5bc64bc3c3a3682d4e07de57',\n",
       "    'order': 2},\n",
       "   {'adult': False,\n",
       "    'gender': 0,\n",
       "    'id': 2152444,\n",
       "    'known_for_department': 'Acting',\n",
       "    'name': 'Philip M. Hofman',\n",
       "    'original_name': 'Philip M. Hofman',\n",
       "    'popularity': 0.6,\n",
       "    'profile_path': None,\n",
       "    'cast_id': 4,\n",
       "    'character': '',\n",
       "    'credit_id': '5bc64bc9c3a3682d60089f96',\n",
       "    'order': 3}],\n",
       "  'crew': [{'adult': False,\n",
       "    'gender': 0,\n",
       "    'id': 1473878,\n",
       "    'known_for_department': 'Directing',\n",
       "    'name': 'Seth Boyden',\n",
       "    'original_name': 'Seth Boyden',\n",
       "    'popularity': 0.694,\n",
       "    'profile_path': None,\n",
       "    'credit_id': '557063d092514140ca0016ef',\n",
       "    'department': 'Directing',\n",
       "    'job': 'Director'},\n",
       "   {'adult': False,\n",
       "    'gender': 1,\n",
       "    'id': 1817484,\n",
       "    'known_for_department': 'Sound',\n",
       "    'name': 'Pinhua Chen',\n",
       "    'original_name': 'Pinhua Chen',\n",
       "    'popularity': 0.6,\n",
       "    'profile_path': None,\n",
       "    'credit_id': '5dff0d77d1a8930019897ff7',\n",
       "    'department': 'Sound',\n",
       "    'job': 'Sound Designer'},\n",
       "   {'adult': False,\n",
       "    'gender': 0,\n",
       "    'id': 2152445,\n",
       "    'known_for_department': 'Sound',\n",
       "    'name': 'Julian Beutel',\n",
       "    'original_name': 'Julian Beutel',\n",
       "    'popularity': 0.6,\n",
       "    'profile_path': None,\n",
       "    'credit_id': '5bc64bd40e0a266e57085a06',\n",
       "    'department': 'Sound',\n",
       "    'job': 'Original Music Composer'}]}}"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "movie = requests.get(\"https://api.themoviedb.org/3/movie/337800\", params = details_params).json()\n",
    "movie"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "e072ac8e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "ids_movies = csv_to_dict(f'data/ids_movies_{start_year}-{end_year}.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "f81f4d4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_tasks_details(session, url_details, details_params, ids_movies):\n",
    "    tasks = []\n",
    "    for id_movie, processing_state in ids_movies.items():\n",
    "        if processing_state==0:\n",
    "            tasks.append(session.get(url_details + str(id_movie), params=details_params, timeout = 15))\n",
    "    return tasks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "d7ae4580",
   "metadata": {},
   "outputs": [],
   "source": [
    "async def details_api_call(url, details_params, ids_movies, output_file, max_tries=3):\n",
    "    exceptions = []\n",
    "    movie_counter = 0\n",
    "    try_counter = 0\n",
    "    max_step = 1000\n",
    "    step = max_step\n",
    "    existing_ids = set()\n",
    "    if os.path.exists(output_file):\n",
    "        with open(output_file, \"r\") as f:\n",
    "            for line in f:\n",
    "                movie = json.loads(line)\n",
    "                existing_ids.add(str(movie['id']))\n",
    "    with open(output_file, \"a\") as f:\n",
    "        while try_counter < max_tries:\n",
    "            async with aiohttp.ClientSession() as session:\n",
    "                tasks = get_tasks_details(session, url, details_params, ids_movies)\n",
    "                if not tasks:\n",
    "                    return exceptions\n",
    "                if len(tasks) < max_step:\n",
    "                    step = len(tasks)\n",
    "                for i in range(0, len(tasks), step):\n",
    "                    batch = tasks[i:i+step]\n",
    "                    responses = await asyncio.gather(*batch, return_exceptions=True)\n",
    "                    for response in responses:\n",
    "                        try:\n",
    "                            movie = await response.json()\n",
    "                            if movie['id'] and str(movie['id']) not in existing_ids:\n",
    "                                json.dump(movie, f)\n",
    "                                f.write('\\n')\n",
    "                                existing_ids.add(str(movie['id']))\n",
    "                                ids_movies[str(movie['id'])] = 1\n",
    "                                movie_counter += 1\n",
    "                                clear_output(wait=True)\n",
    "                                print(f'{movie_counter} movies out of {len(ids_movies)} have been fetched')\n",
    "                        except:\n",
    "                            exceptions.append(response)\n",
    "            try_counter += 1\n",
    "    return exceptions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "ed263c3c",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4534 movies out of 4534 have been fetched\n",
      "Elapsed time: 25.42 seconds\n"
     ]
    }
   ],
   "source": [
    "start = time.monotonic()\n",
    "detailed_movies = await details_api_call(url_details, details_params, ids_movies, output_file = 'data/processed_movies_ids.jsonl')\n",
    "end = time.monotonic()\n",
    "\n",
    "print(f'Elapsed time: {round(end - start, 2)} seconds')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "480ea6d2",
   "metadata": {},
   "source": [
    "### Streaming companies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "73d2deca",
   "metadata": {},
   "outputs": [],
   "source": [
    "ids_movies = csv_to_dict(f'data/ids_movies_{start_year}-{end_year}.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "f05e4ca7",
   "metadata": {},
   "outputs": [],
   "source": [
    "str_comps_url = \"https://api.themoviedb.org/3/movie/\"\n",
    "\n",
    "str_comps_endpoint = \"/watch/providers\"\n",
    "\n",
    "str_comp_params = {\n",
    "                \"api_key\": api_key,\n",
    "                \"watch-region\": \"ES\"\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "828b06fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_tasks_str_comps(session, url_str_comp, str_comps_endpoint, str_comp_params, ids_movies):\n",
    "    tasks = []\n",
    "    for id_movie, processing_state in ids_movies.items():\n",
    "        if processing_state==0:\n",
    "            tasks.append(session.get(str_comps_url + str(id_movie) + str_comps_endpoint, params=str_comp_params, timeout = 15))\n",
    "    return tasks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "f7329940",
   "metadata": {},
   "outputs": [],
   "source": [
    "async def str_comp_api_call(str_comps_url, str_comps_endpoint, str_comp_params, ids_movies, output_file, max_tries=3):\n",
    "    exceptions = []\n",
    "    movie_counter = 0\n",
    "    try_counter = 0\n",
    "    max_step = 1000\n",
    "    step = max_step\n",
    "    existing_ids = set()\n",
    "    if os.path.exists(output_file):\n",
    "        with open(output_file, \"r\") as f:\n",
    "            for line in f:\n",
    "                movie = json.loads(line)\n",
    "                existing_ids.add(str(movie['id']))\n",
    "                movie_counter += 1\n",
    "                ids_movies[str(movie['id'])] = 1\n",
    "    with open(output_file, \"a\") as f:\n",
    "        while try_counter < max_tries:\n",
    "            async with aiohttp.ClientSession() as session:\n",
    "                tasks = get_tasks_str_comps(session, str_comps_url, str_comps_endpoint,str_comp_params, ids_movies)\n",
    "                if not tasks:\n",
    "                    return exceptions, movie_counter\n",
    "                if len(tasks) < max_step:\n",
    "                    step = len(tasks)\n",
    "                for i in range(0, len(tasks), step):\n",
    "                    batch = tasks[i:i+step]\n",
    "                    responses = await asyncio.gather(*batch, return_exceptions=True)\n",
    "                    for response in responses:\n",
    "                        try:\n",
    "                            str_comps = await response.json()\n",
    "                            if str(str_comps['id']) not in existing_ids:\n",
    "                                json.dump(str_comps, f)\n",
    "                                f.write('\\n')\n",
    "                                existing_ids.add(str(str_comps['id']))\n",
    "                                ids_movies[str(str_comps['id'])] = 1\n",
    "                                movie_counter += 1\n",
    "                                clear_output(wait=True)\n",
    "                                print(f'Watch providers for {movie_counter} movies out of {len(ids_movies)} have been fetched')\n",
    "                        except:\n",
    "                            exceptions.append(response)\n",
    "            try_counter += 1\n",
    "    return exceptions, movie_counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "3e2cb539",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Watch providers for 4534 movies out of 4534 have been fetched\n",
      "Elapsed time: 18.34 seconds\n"
     ]
    }
   ],
   "source": [
    "start = time.monotonic()\n",
    "exceptions, movie_counter = await str_comp_api_call(str_comps_url, str_comps_endpoint, str_comp_params, ids_movies, output_file = 'data/str_comps.jsonl', max_tries=3)\n",
    "end = time.monotonic()\n",
    "\n",
    "print(f'Elapsed time: {round(end - start, 2)} seconds')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12d4f3d4",
   "metadata": {},
   "source": [
    "### Table population"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "baa00f77",
   "metadata": {},
   "outputs": [],
   "source": [
    "def populate_movie(movies):\n",
    "    insert_query = \"\"\"\n",
    "    INSERT INTO movie\n",
    "    (id_movie, original_title, original_language, overview, popularity, poster_path, release_date, title, vote_average, vote_count, budget, revenue, runtime)\n",
    "    VALUES(%s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s)\n",
    "    \"\"\"\n",
    "    \n",
    "    records = [(m['id'], m['original_title'], m['original_language'], m['overview'], m['popularity'], m['poster_path'], m['release_date'], m['title'], m['vote_average'], m['vote_count'], m['budget'], m['revenue'], m['runtime']) for m in movies]\n",
    "    \n",
    "    cursor.executemany(insert_query, records)\n",
    "    \n",
    "    db.commit()\n",
    "    \n",
    "    return cursor.rowcount"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "ce3159c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def populate_prod_comp(movies):\n",
    "    insert_query = \"\"\"\n",
    "    INSERT IGNORE INTO prod_comp\n",
    "    (id_prod_comp, name, origin_country)\n",
    "    VALUES(%s, %s, %s)\n",
    "    \"\"\"\n",
    "    \n",
    "    prod_comps = [(prod_comp['id'], \n",
    "                   prod_comp['name'], \n",
    "                   prod_comp['origin_country']) \n",
    "                  for movie in movies\n",
    "                  for prod_comp in movie['production_companies']]\n",
    "                              \n",
    "    cursor.executemany(insert_query, prod_comps)\n",
    "    db.commit()\n",
    "    \n",
    "    return cursor.rowcount"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "65bdbe9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def populate_movie_prod_comp(movies):\n",
    "    insert_query = \"\"\"\n",
    "    INSERT INTO movie_prod_comp\n",
    "    (id_movie, id_prod_comp)\n",
    "    VALUES(%s, %s)\n",
    "    \"\"\"\n",
    "    \n",
    "    movie_prod_comp = [(m['id'],\n",
    "                        prod_comp['id']) \n",
    "                       for m in movies \n",
    "                       for prod_comp in m['production_companies']]\n",
    "    \n",
    "    cursor.executemany(insert_query, movie_prod_comp)\n",
    "    \n",
    "    db.commit()\n",
    "    \n",
    "    return cursor.rowcount"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "ab3756ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "def populate_movie_genre(movies):\n",
    "    insert_query = \"\"\"\n",
    "    INSERT INTO movie_genre\n",
    "    (id_movie, id_genre)\n",
    "    VALUES(%s, %s)\n",
    "    \"\"\"\n",
    "    movie_genre = [(m['id'], \n",
    "                     genre['id']) \n",
    "                    for m in movies \n",
    "                    for genre in m['genres']]\n",
    "    \n",
    "    cursor.executemany(insert_query, movie_genre)\n",
    "    \n",
    "    db.commit()\n",
    "    \n",
    "    return cursor.rowcount"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "6a6d94e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def populate_person(movies, jobs):\n",
    "    insert_query = \"\"\"\n",
    "    INSERT IGNORE INTO person\n",
    "    (id_person, name, gender)\n",
    "    VALUES(%s, %s, %s)\n",
    "    \"\"\"\n",
    "    \n",
    "    actors = [(actor['id'], \n",
    "               actor['name'], \n",
    "               actor['gender']) \n",
    "              for m in movies \n",
    "              for actor in m['credits']['cast'][0:7]]\n",
    "    \n",
    "    crew = [(crew_mem['id'], \n",
    "             crew_mem['name'], \n",
    "             crew_mem['gender']) \n",
    "            for m in movies \n",
    "            for crew_mem in m['credits']['crew']\n",
    "            if crew_mem['job'] in jobs]\n",
    "    \n",
    "    cursor.executemany(insert_query, actors + crew)\n",
    "    \n",
    "    db.commit()\n",
    "    \n",
    "    return cursor.rowcount"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "ae20b46c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def populate_movie_person(movies, jobs):\n",
    "    insert_query = \"\"\"\n",
    "    INSERT INTO movie_person\n",
    "    (id_movie, id_person, id_job)\n",
    "    VALUES(%s, %s, %s)\n",
    "    \"\"\"\n",
    "    \n",
    "    movies_actors = [(m['id'], \n",
    "                      actor['id'], \n",
    "                      jobs.index('Actor') + 1)\n",
    "                     for m in movies \n",
    "                     for actor in m['credits']['cast'][0:7]]\n",
    "    \n",
    "    movies_crew = [(m['id'], \n",
    "                    crew_mem['id'], \n",
    "                    jobs.index(crew_mem['job']) + 1) \n",
    "                   for m in movies \n",
    "                   for crew_mem in m['credits']['crew']\n",
    "                   if crew_mem['job'] in jobs]\n",
    "    \n",
    "    cursor.executemany(insert_query, movies_actors + movies_crew)\n",
    "    \n",
    "    db.commit()\n",
    "    \n",
    "    return cursor.rowcount"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "62ad3818",
   "metadata": {},
   "outputs": [],
   "source": [
    "def populate_movie_str_comp(str_comps):\n",
    "    \n",
    "    insert_query = \"\"\"\n",
    "    INSERT INTO movie_str_comp\n",
    "    (id_movie, id_str_comp)\n",
    "    VALUES(%s, %s)\n",
    "    \"\"\"\n",
    "    flatrate_es_comps = []\n",
    "    \n",
    "    for str_comp in str_comps:\n",
    "        id_movie = str_comp.get(\"id\")\n",
    "        flatrates = str_comp.get(\"results\", {}).get(\"ES\", {}).get(\"flatrate\", [])\n",
    "        for flatrate in flatrates:\n",
    "            provider_id = flatrate.get(\"provider_id\")\n",
    "            flatrate_es_comps.append((id_movie, provider_id))\n",
    "    \n",
    "    cursor.executemany(insert_query, flatrate_es_comps)\n",
    "    \n",
    "    db.commit()\n",
    "    \n",
    "    return cursor.rowcount"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "00287543",
   "metadata": {},
   "outputs": [],
   "source": [
    "jobs = ['Actor', 'Director','Screenplay']\n",
    "\n",
    "# Define the chunk size\n",
    "chunk_size = 1000\n",
    "\n",
    "# Read the JSONL file in chunks\n",
    "for chunk in pd.read_json('data/processed_movies_ids.jsonl', lines=True, chunksize=chunk_size):\n",
    "    # Convert the chunk to a list of dictionaries\n",
    "    movies = chunk.to_dict(orient='records')\n",
    "    \n",
    "    populate_movie(movies)\n",
    "    populate_prod_comp(movies)\n",
    "    populate_movie_prod_comp(movies)\n",
    "    populate_movie_genre(movies)\n",
    "    populate_person(movies, jobs)\n",
    "    populate_movie_person(movies, jobs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "ecbc5035",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Define the chunk size\n",
    "chunk_size = 1000\n",
    "\n",
    "for chunk in pd.read_json('data/str_comps.jsonl', lines=True, chunksize=chunk_size):\n",
    "    # Convert the chunk to a list of dictionaries\n",
    "    str_comps = chunk.to_dict(orient='records')\n",
    "    \n",
    "    populate_movie_str_comp(str_comps)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45a87497",
   "metadata": {},
   "source": [
    "## EDA (Exploratory Data Analysis)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b74a4ba",
   "metadata": {},
   "source": [
    "## Recommendation model"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": true,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "357.487px"
   },
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
